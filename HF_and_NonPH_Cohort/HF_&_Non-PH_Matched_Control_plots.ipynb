{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "    <h2><center>Matched Control Cohort (Using demographic covariants) </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center> Regression Model Using propensity_score to create Matched Control Cohorts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "#dataset_for_matched_control_cohort = pd.read_csv('Dataset for Matched Control Cohort.csv')\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['Date of Death', 'Death Cause Diseases', 'Death Cause Disease ICD10 Codes']\n",
    "dataset_for_matched_control_cohort.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values in the specific columns\n",
    "dataset_for_matched_control_cohort.dropna(subset=['Combined ICD10 Codes', 'Participant ID', 'IMD_quintile'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(dataset_for_matched_control_cohort[['Sex', 'Ethnicity', 'Age Range', 'Smoking Status', 'BMI Range', 'IMD_quintile', 'Alive / Dead']], drop_first=True)\n",
    "\n",
    "# Logistic Regression to calculate propensity scores\n",
    "X = df_encoded\n",
    "y = dataset_for_matched_control_cohort['Combined ICD10 Codes'].apply(lambda x: 1 if any(code in str(x) for code in ['I27.0', 'I27.2', 'I27.9']) else 0)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "dataset_for_matched_control_cohort['propensity_score'] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Create treatment and control groups\n",
    "ph_cohort_group = dataset_for_matched_control_cohort[dataset_for_matched_control_cohort['Combined ICD10 Codes'].str.contains('I27.0|I27.2|I27.9', na=False)]\n",
    "\n",
    "# Ensure control group does not include participants in the PH cohort\n",
    "control_group = dataset_for_matched_control_cohort[~dataset_for_matched_control_cohort['Participant ID'].isin(ph_cohort_group['Participant ID'])]\n",
    "\n",
    "# Perform nearest neighbor matching\n",
    "caliper = 0.05\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(control_group[['propensity_score']])\n",
    "distances, indices = nn.kneighbors(ph_cohort_group[['propensity_score']])\n",
    "\n",
    "# Apply caliper and select the matched controls\n",
    "matched_controls_indices = [index for distance, index in zip(distances.flatten(), indices.flatten()) if distance <= caliper]\n",
    "\n",
    "# Check if enough controls are matched within the caliper\n",
    "if len(matched_controls_indices) < len(ph_cohort_group):\n",
    "    print(f\"Initial matching resulted in {len(matched_controls_indices)} controls. Expanding caliper.\")\n",
    "    \n",
    "    # Expand caliper incrementally until we have enough matches\n",
    "    while len(matched_controls_indices) < len(ph_cohort_group):\n",
    "        caliper += 0.01\n",
    "        matched_controls_indices = [index for distance, index in zip(distances.flatten(), indices.flatten()) if distance <= caliper]\n",
    "        print(f\"Caliper: {caliper}, Matches: {len(matched_controls_indices)}\")\n",
    "\n",
    "# Ensure we only take the first len(ph_cohort_group) matches if we have more\n",
    "matched_controls_indices = matched_controls_indices[:len(ph_cohort_group)]\n",
    "\n",
    "matched_controls = control_group.iloc[matched_controls_indices]\n",
    "matched_controls = matched_controls.drop_duplicates(subset='Participant ID')\n",
    "\n",
    "# Ensure the number of matched controls is the same as the PH cohort\n",
    "while matched_controls['Participant ID'].nunique() < len(ph_cohort_group):\n",
    "    deficit = len(ph_cohort_group) - matched_controls['Participant ID'].nunique()\n",
    "    additional_controls = control_group.drop(matched_controls.index).sample(n=deficit, replace=False)\n",
    "    matched_controls = pd.concat([matched_controls, additional_controls]).drop_duplicates(subset='Participant ID')\n",
    "\n",
    "# Ensure the number of matched controls is exactly 2441 unique participants\n",
    "matched_controls = matched_controls.drop_duplicates(subset='Participant ID').sample(n=2441, replace=False)\n",
    "\n",
    "# Combine PH patients and matched controls\n",
    "Combine_PH_and_matched_cohort = pd.concat([ph_cohort_group, matched_controls])\n",
    "Combine_PH_and_matched_cohort = Combine_PH_and_matched_cohort.reset_index(drop=True)\n",
    "\n",
    "# Display the number of unique Participant IDs in each group\n",
    "unique_ph_ids = ph_cohort_group['Participant ID'].nunique()\n",
    "unique_matched_control_ids = matched_controls['Participant ID'].nunique()\n",
    "\n",
    "print(f\"Number of unique Participant IDs in PH Cohort: {unique_ph_ids}\")\n",
    "print(f\"Number of unique Participant IDs in Matched Control Cohort: {unique_matched_control_ids}\")\n",
    "\n",
    "# Display the matched cohort\n",
    "print(\"Matched Control Cohort:\\n\")\n",
    "print(f\"Number of participants in Matched Control Cohort: {len(matched_controls)}\")\n",
    "display(matched_controls.head(5))\n",
    "print()\n",
    "\n",
    "# Display the combined cohort\n",
    "print(\"Combine PH patients and matched controls:\\n\")\n",
    "print(f\"Number of participants in Combined Cohort: {len(Combine_PH_and_matched_cohort)}\")\n",
    "display(Combine_PH_and_matched_cohort.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlaps\n",
    "#common_participants = pd.merge(ph_cohort_group, matched_controls, on='Participant ID', how='inner')\n",
    "\n",
    "#if common_participants.empty:\n",
    "#    print(\"No overlapping participants between PH cohort and matched controls.\")\n",
    "#else:\n",
    "#    print(f\"Found {len(common_participants)} overlapping participants between PH cohort and matched controls.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify the file path where you want to save the CSV file\n",
    "#file_path = 'MATCHED Control Cohort Dataset.csv'\n",
    "\n",
    "#### Use the to_csv method to save the DataFrame as a CSV file\n",
    "#matched_controls.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "matched_controls = []\n",
    "matched_controls = pd.read_csv('MATCHED Control Cohort Dataset.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_matched_controls = {}\n",
    "row_counts_matched_controls = {}\n",
    "nan_counts_matched_controls = {}\n",
    "empty_counts_matched_controls = {}\n",
    "prefer_not_to_say_counts_matched_controls = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_matched_controls in matched_controls.columns:\n",
    "    unique_count_matched_controls = matched_controls[column_matched_controls].nunique()\n",
    "    row_count_matched_controls = len(matched_controls[column_matched_controls])\n",
    "    nan_count_matched_controls = matched_controls[column_matched_controls].isna().sum()  # Count NaN values\n",
    "    empty_count_matched_controls = matched_controls[column_matched_controls].eq('').sum()  # Count empty string values\n",
    "    prefer_not_to_say_count_matched_controls = matched_controls[column_matched_controls].eq('Prefer not to answer').sum()  \n",
    "\n",
    "    unique_counts_matched_controls[column_matched_controls] = [unique_count_matched_controls]\n",
    "    row_counts_matched_controls[column_matched_controls] = [row_count_matched_controls]\n",
    "    nan_counts_matched_controls[column_matched_controls] = [nan_count_matched_controls]\n",
    "    empty_counts_matched_controls[column_matched_controls] = [empty_count_matched_controls]\n",
    "    prefer_not_to_say_counts_matched_controls[column_matched_controls] = [prefer_not_to_say_count_matched_controls]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_matched_control = []\n",
    "row_counts_matched_control = []\n",
    "nan_counts_matched_control = []\n",
    "empty_counts_matched_control = []\n",
    "prefer_not_to_say_counts_matched_control =[]\n",
    "\n",
    "unique_counts_matched_control = pd.DataFrame(unique_counts_matched_controls, index=['Unique Count'])\n",
    "row_counts_matched_control = pd.DataFrame(row_counts_matched_controls, index=['Row Count'])\n",
    "nan_counts_matched_control = pd.DataFrame(nan_counts_matched_controls, index=['NaN Count'])\n",
    "empty_counts_matched_control = pd.DataFrame(empty_counts_matched_controls, index=['Empty Count'])\n",
    "prefer_not_to_say_counts_matched_control = pd.DataFrame(prefer_not_to_say_counts_matched_controls, index=['Prefer not to answer'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_matched_controls = []\n",
    "result_matched_controls = pd.concat([unique_counts_matched_control, row_counts_matched_control, nan_counts_matched_control, empty_counts_matched_control,prefer_not_to_say_counts_matched_control])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"matched_controls:\")\n",
    "display(result_matched_controls)\n",
    "print()\n",
    "print()\n",
    "display(matched_controls.head(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>Sex and Ethnicity Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of each sex\n",
    "sex_counts = []\n",
    "sex_counts = unique_participants['Sex'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "sex_percentages = []\n",
    "sex_percentages = (sex_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "sex_counts_with_percentages = []\n",
    "sex_counts_with_percentages = sex_counts.astype(str) + \" (\" + sex_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "missing_counts = []\n",
    "missing_counts = unique_participants.isna().sum()\n",
    "\n",
    "# Get unique items in the \"Ethnicity\" column\n",
    "unique_ethnicities = []\n",
    "unique_ethnicities = unique_participants['Ethnicity'].unique()\n",
    "\n",
    "# Count the number of each unique ethnicity\n",
    "ethnicity_counts = []\n",
    "ethnicity_counts = unique_participants['Ethnicity'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "ethnicity_percentages = []\n",
    "ethnicity_percentages = (ethnicity_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "ethnicity_counts_with_percentages = []\n",
    "ethnicity_counts_with_percentages = ethnicity_counts.astype(str) + \" (\" + ethnicity_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "# Print the counts\n",
    "print(\"Sex Counts with Percentages:\")\n",
    "print(sex_counts_with_percentages)\n",
    "print()\n",
    "print(\"\\nEthnicity Counts with Percentages:\")\n",
    "print(ethnicity_counts_with_percentages)\n",
    "print()\n",
    "print(\"\\nMissing Values Counts:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>Age Groups Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "# Count occurrences of each age range\n",
    "age_range_counts = []\n",
    "age_range_counts = unique_participants['Age Range'].value_counts().sort_index()\n",
    "\n",
    "# Calculate percentages\n",
    "age_range_percentages = (age_range_counts / total_participants) * 100\n",
    "\n",
    "# Display the results\n",
    "for age_range, count in age_range_counts.items():\n",
    "    percentage = age_range_percentages[age_range]\n",
    "    print(f\"{age_range} : {count} ({percentage:.2f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>Smoking Status Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"Smoking Status\"\n",
    "unique_smoking_status = []\n",
    "unique_smoking_status = unique_participants['Smoking Status'].unique()\n",
    "# Print the unique items\n",
    "display(unique_smoking_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'Smoking Status' column\n",
    "smoking_status_counts = []\n",
    "smoking_status_counts = unique_participants['Smoking Status'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "smoking_status_percentages = []\n",
    "smoking_status_percentages = (smoking_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "smoking_status_counts_with_percentages = []\n",
    "smoking_status_counts_with_percentages = smoking_status_counts.astype(str) + \" (\" + smoking_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'Smoking Status' column:\")\n",
    "display(smoking_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>BMI Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"BMI Range\"\n",
    "unique_BMI_status = []\n",
    "unique_BMI_status = unique_participants['BMI Range'].unique()\n",
    "# Print the unique items\n",
    "display(unique_BMI_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'BMI Range' column\n",
    "BMI_status_counts = []\n",
    "BMI_status_counts = unique_participants['BMI Range'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "BMI_status_percentages = []\n",
    "BMI_status_percentages = (BMI_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "BMI_status_counts_with_percentages = []\n",
    "BMI_status_counts_with_percentages = BMI_status_counts.astype(str) + \" (\" + BMI_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'BMI Range' column:\")\n",
    "display(BMI_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>IMD Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"IMD_quintile\"\n",
    "unique_IMD_status = []\n",
    "unique_IMD_status = unique_participants['IMD_quintile'].unique()\n",
    "# Print the unique items\n",
    "display(unique_IMD_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'IMD_quintile' column\n",
    "IMD_status_counts = []\n",
    "IMD_status_counts = unique_participants['IMD_quintile'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "IMD_status_percentages = []\n",
    "IMD_status_percentages = (IMD_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "IMD_status_counts_with_percentages = []\n",
    "IMD_status_counts_with_percentages = IMD_status_counts.astype(str) + \" (\" + IMD_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'IMD_quintile' column:\")\n",
    "display(IMD_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E6E6FA; padding: 10px;\">\n",
    "    <h2><center>Age Specific Mortality Counts for Non-PH Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "# Count occurrences of unique values in the 'Alive / Dead' column\n",
    "total_alive_dead_counts = []\n",
    "total_alive_dead_counts = unique_participants['Alive / Dead'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "total_alive_dead_percentages = []\n",
    "total_alive_dead_percentages = (total_alive_dead_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "total_alive_dead_counts_with_percentages = []\n",
    "total_alive_dead_counts_with_percentages = total_alive_dead_counts.astype(str) + \" (\" + total_alive_dead_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'Alive / Dead' column:\")\n",
    "display(total_alive_dead_counts_with_percentages)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Assume the DataFrame is already loaded as All_ICD10_with_Diseases_Dates_Data\n",
    "\n",
    "# Define the age ranges\n",
    "bins = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = [\"30 - 40\", \"41 - 50\", \"51 - 60\", \"61 - 70\", \"71 - 80\", \"81 - 90\", \"91 - 100\"]\n",
    "\n",
    "\n",
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "# Separate the counts for 'Alive' and 'Dead' within each age range\n",
    "alive_counts = []\n",
    "dead_counts = []\n",
    "alive_counts = unique_participants[unique_participants['Alive / Dead'] == 'Alive']['Age Range'].value_counts().sort_index()\n",
    "dead_counts = unique_participants[unique_participants['Alive / Dead'] == 'Dead']['Age Range'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the percentages\n",
    "alive_percentages = []\n",
    "dead_percentages = []\n",
    "alive_percentages = (alive_counts / total_participants) * 100\n",
    "dead_percentages = (dead_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages for 'Alive'\n",
    "alive_counts_with_percentages = alive_counts.astype(str) + \" (\" + alive_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "# Combine counts and percentages for 'Dead'\n",
    "dead_counts_with_percentages = []\n",
    "dead_counts_with_percentages = dead_counts.astype(str) + \" (\" + dead_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "# Display the counts and percentages for 'Alive'\n",
    "print(\"Counts and percentages for 'Alive' in each age range:\")\n",
    "display(alive_counts_with_percentages)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Display the counts and percentages for 'Dead'\n",
    "print(\"Counts and percentages for 'Dead' in each age range:\")\n",
    "display(dead_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Heart Failure Matched Control Cohort   </center></h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will generate the Heart Failure Matched Control Cohort using **I50.0** and **I50.1** in comparison to PH Cohort for forest plot, sunburst plot, table, tracer plot and Cox Hazard Ratio plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "matched_controls = []\n",
    "matched_controls = pd.read_csv('Dataset for Matched Control Cohort.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_matched_controls = {}\n",
    "row_counts_matched_controls = {}\n",
    "nan_counts_matched_controls = {}\n",
    "empty_counts_matched_controls = {}\n",
    "prefer_not_to_say_counts_matched_controls = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_matched_controls in matched_controls.columns:\n",
    "    unique_count_matched_controls = matched_controls[column_matched_controls].nunique()\n",
    "    row_count_matched_controls = len(matched_controls[column_matched_controls])\n",
    "    nan_count_matched_controls = matched_controls[column_matched_controls].isna().sum()  # Count NaN values\n",
    "    empty_count_matched_controls = matched_controls[column_matched_controls].eq('').sum()  # Count empty string values\n",
    "    prefer_not_to_say_count_matched_controls = matched_controls[column_matched_controls].eq('Prefer not to answer').sum()  \n",
    "\n",
    "    unique_counts_matched_controls[column_matched_controls] = [unique_count_matched_controls]\n",
    "    row_counts_matched_controls[column_matched_controls] = [row_count_matched_controls]\n",
    "    nan_counts_matched_controls[column_matched_controls] = [nan_count_matched_controls]\n",
    "    empty_counts_matched_controls[column_matched_controls] = [empty_count_matched_controls]\n",
    "    prefer_not_to_say_counts_matched_controls[column_matched_controls] = [prefer_not_to_say_count_matched_controls]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_matched_control = []\n",
    "row_counts_matched_control = []\n",
    "nan_counts_matched_control = []\n",
    "empty_counts_matched_control = []\n",
    "prefer_not_to_say_counts_matched_control =[]\n",
    "\n",
    "unique_counts_matched_control = pd.DataFrame(unique_counts_matched_controls, index=['Unique Count'])\n",
    "row_counts_matched_control = pd.DataFrame(row_counts_matched_controls, index=['Row Count'])\n",
    "nan_counts_matched_control = pd.DataFrame(nan_counts_matched_controls, index=['NaN Count'])\n",
    "empty_counts_matched_control = pd.DataFrame(empty_counts_matched_controls, index=['Empty Count'])\n",
    "prefer_not_to_say_counts_matched_control = pd.DataFrame(prefer_not_to_say_counts_matched_controls, index=['Prefer not to answer'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_matched_controls = []\n",
    "result_matched_controls = pd.concat([unique_counts_matched_control, row_counts_matched_control, nan_counts_matched_control, empty_counts_matched_control,prefer_not_to_say_counts_matched_control])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"matched_controls_heart_failure:\")\n",
    "display(result_matched_controls)\n",
    "print()\n",
    "print()\n",
    "\n",
    "dataset_for_matched_control_cohort = []\n",
    "dataset_for_matched_control_cohort = matched_controls\n",
    "display(dataset_for_matched_control_cohort.head(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = ['Death Cause Diseases', 'Death Cause Disease ICD10 Codes']\n",
    "dataset_for_matched_control_cohort.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values in the specific columns\n",
    "dataset_for_matched_control_cohort.dropna(subset=['Combined ICD10 Codes', 'Participant ID', 'IMD_quintile'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(dataset_for_matched_control_cohort[['Sex', 'Ethnicity', 'Age Range', 'Smoking Status', 'BMI Range', 'IMD_quintile', 'Alive / Dead']], drop_first=True)\n",
    "\n",
    "# Identify PH and COPD cohorts\n",
    "ph_codes = ['I27.0', 'I27.2', 'I27.9']\n",
    "heart_failure_codes = ['I50.0', 'I50.1']\n",
    "\n",
    "dataset_for_matched_control_cohort['PH'] = dataset_for_matched_control_cohort['Combined ICD10 Codes'].apply(lambda x: 1 if any(code in str(x) for code in ph_codes) else 0)\n",
    "dataset_for_matched_control_cohort['Heart_Failure'] = dataset_for_matched_control_cohort['Combined ICD10 Codes'].apply(lambda x: 1 if any(code in str(x) for code in heart_failure_codes) else 0)\n",
    "dataset_for_matched_control_cohort.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression for propensity score calculation for COPD as control\n",
    "model = LogisticRegression(max_iter=1000)  # Increase max_iter to ensure convergence\n",
    "model.fit(df_encoded, dataset_for_matched_control_cohort['Heart_Failure'])\n",
    "dataset_for_matched_control_cohort['propensity_score'] = model.predict_proba(df_encoded)[:, 1]\n",
    "\n",
    "# PH cohort as treatment group\n",
    "ph_cohort_group = dataset_for_matched_control_cohort[dataset_for_matched_control_cohort['PH'] == 1]\n",
    "\n",
    "# COPD cohort as control group\n",
    "# Ensure control group does not include participants in the PH cohort\n",
    "heart_failure_control_group = dataset_for_matched_control_cohort[(dataset_for_matched_control_cohort['Heart_Failure'] == 1) & (~dataset_for_matched_control_cohort['Participant ID'].isin(ph_cohort_group['Participant ID']))]\n",
    "\n",
    "# Perform nearest neighbor matching\n",
    "caliper = 0.05\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(heart_failure_control_group[['propensity_score']])\n",
    "distances, indices = nn.kneighbors(ph_cohort_group[['propensity_score']])\n",
    "\n",
    "# Apply caliper and select the matched controls\n",
    "matched_controls_indices = [index for distance, index in zip(distances.flatten(), indices.flatten()) if distance <= caliper]\n",
    "\n",
    "# Expand caliper incrementally until we have enough matches\n",
    "if len(matched_controls_indices) < 2441:\n",
    "    print(f\"Initial matching resulted in {len(matched_controls_indices)} controls. Expanding caliper.\")\n",
    "    \n",
    "    while len(matched_controls_indices) < 2441:\n",
    "        caliper += 0.01\n",
    "        distances, indices = nn.kneighbors(ph_cohort_group[['propensity_score']])\n",
    "        matched_controls_indices = [index for distance, index in zip(distances.flatten(), indices.flatten()) if distance <= caliper]\n",
    "        print(f\"Caliper: {caliper}, Matches: {len(matched_controls_indices)}\")\n",
    "\n",
    "# Ensure we only take the first 2441 matches if we have more\n",
    "matched_controls_indices = matched_controls_indices[:2441]\n",
    "\n",
    "# Select matched controls and ensure the number matches 2441\n",
    "matched_controls = heart_failure_control_group.iloc[matched_controls_indices]\n",
    "matched_controls = matched_controls.drop_duplicates(subset='Participant ID')\n",
    "\n",
    "# If the number of unique matched controls is less than 2441, adjust by adding more samples if necessary\n",
    "while matched_controls['Participant ID'].nunique() < 2441:\n",
    "    deficit = 2441 - matched_controls['Participant ID'].nunique()\n",
    "    additional_controls = heart_failure_control_group.drop(matched_controls.index).sample(n=deficit, replace=True)\n",
    "    matched_controls = pd.concat([matched_controls, additional_controls]).drop_duplicates(subset='Participant ID')\n",
    "\n",
    "# Ensure the number of matched controls is exactly 2441 by sampling if necessary\n",
    "if matched_controls['Participant ID'].nunique() < 2441:\n",
    "    matched_controls = matched_controls.sample(n=2441, replace=True)\n",
    "\n",
    "# Combine PH patients and matched controls\n",
    "Combine_PH_and_matched_control_cohort = pd.concat([ph_cohort_group, matched_controls])\n",
    "Combine_PH_and_matched_control_cohort = Combine_PH_and_matched_control_cohort.reset_index(drop=True)\n",
    "\n",
    "# Display the number of unique Participant IDs in each group\n",
    "unique_ph_ids = ph_cohort_group['Participant ID'].nunique()\n",
    "unique_matched_control_ids = matched_controls['Participant ID'].nunique()\n",
    "\n",
    "print(f\"Number of unique Participant IDs in PH Cohort: {unique_ph_ids}\")\n",
    "print(f\"Number of unique Participant IDs in Heart Failure Matched Control Cohort: {unique_matched_control_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlaps\n",
    "common_participants = pd.merge(ph_cohort_group, matched_controls, on='Participant ID', how='inner')\n",
    "\n",
    "if common_participants.empty:\n",
    "    print(\"No overlapping participants between PH cohort and matched controls.\")\n",
    "else:\n",
    "    print(f\"Found {len(common_participants)} overlapping participants between PH cohort and matched controls.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Heart Failure matched Control Cohort Dataset.csv'\n",
    "\n",
    "#### Use the to_csv method to save the DataFrame as a CSV file\n",
    "#matched_controls.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Sex and Ethnicity Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "matched_controls = []\n",
    "matched_controls = pd.read_csv('Heart Failure matched Control Cohort Dataset.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_matched_controls = {}\n",
    "row_counts_matched_controls = {}\n",
    "nan_counts_matched_controls = {}\n",
    "empty_counts_matched_controls = {}\n",
    "prefer_not_to_say_counts_matched_controls = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_matched_controls in matched_controls.columns:\n",
    "    unique_count_matched_controls = matched_controls[column_matched_controls].nunique()\n",
    "    row_count_matched_controls = len(matched_controls[column_matched_controls])\n",
    "    nan_count_matched_controls = matched_controls[column_matched_controls].isna().sum()  # Count NaN values\n",
    "    empty_count_matched_controls = matched_controls[column_matched_controls].eq('').sum()  # Count empty string values\n",
    "    prefer_not_to_say_count_matched_controls = matched_controls[column_matched_controls].eq('Prefer not to answer').sum()  \n",
    "\n",
    "    unique_counts_matched_controls[column_matched_controls] = [unique_count_matched_controls]\n",
    "    row_counts_matched_controls[column_matched_controls] = [row_count_matched_controls]\n",
    "    nan_counts_matched_controls[column_matched_controls] = [nan_count_matched_controls]\n",
    "    empty_counts_matched_controls[column_matched_controls] = [empty_count_matched_controls]\n",
    "    prefer_not_to_say_counts_matched_controls[column_matched_controls] = [prefer_not_to_say_count_matched_controls]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_matched_control = []\n",
    "row_counts_matched_control = []\n",
    "nan_counts_matched_control = []\n",
    "empty_counts_matched_control = []\n",
    "prefer_not_to_say_counts_matched_control =[]\n",
    "\n",
    "unique_counts_matched_control = pd.DataFrame(unique_counts_matched_controls, index=['Unique Count'])\n",
    "row_counts_matched_control = pd.DataFrame(row_counts_matched_controls, index=['Row Count'])\n",
    "nan_counts_matched_control = pd.DataFrame(nan_counts_matched_controls, index=['NaN Count'])\n",
    "empty_counts_matched_control = pd.DataFrame(empty_counts_matched_controls, index=['Empty Count'])\n",
    "prefer_not_to_say_counts_matched_control = pd.DataFrame(prefer_not_to_say_counts_matched_controls, index=['Prefer not to answer'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_matched_controls = []\n",
    "result_matched_controls = pd.concat([unique_counts_matched_control, row_counts_matched_control, nan_counts_matched_control, empty_counts_matched_control,prefer_not_to_say_counts_matched_control])\n",
    "\n",
    "\n",
    "matched_controls_heart_failure = []\n",
    "matched_controls_heart_failure = matched_controls\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"matched_controls:\")\n",
    "display(result_matched_controls)\n",
    "print()\n",
    "print()\n",
    "display(matched_controls_heart_failure.head(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of each sex\n",
    "sex_counts = []\n",
    "sex_counts = unique_participants['Sex'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "sex_percentages = []\n",
    "sex_percentages = (sex_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "sex_counts_with_percentages = []\n",
    "sex_counts_with_percentages = sex_counts.astype(str) + \" (\" + sex_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "missing_counts = []\n",
    "missing_counts = unique_participants.isna().sum()\n",
    "\n",
    "# Get unique items in the \"Ethnicity\" column\n",
    "unique_ethnicities = []\n",
    "unique_ethnicities = unique_participants['Ethnicity'].unique()\n",
    "\n",
    "# Count the number of each unique ethnicity\n",
    "ethnicity_counts = []\n",
    "ethnicity_counts = unique_participants['Ethnicity'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "ethnicity_percentages = []\n",
    "ethnicity_percentages = (ethnicity_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "ethnicity_counts_with_percentages = []\n",
    "ethnicity_counts_with_percentages = ethnicity_counts.astype(str) + \" (\" + ethnicity_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "# Print the counts\n",
    "print(\"Sex Counts with Percentages:\")\n",
    "print(sex_counts_with_percentages)\n",
    "print()\n",
    "print(\"\\nEthnicity Counts with Percentages:\")\n",
    "print(ethnicity_counts_with_percentages)\n",
    "print()\n",
    "print(\"\\nMissing Values Counts:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Age Groups Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "# Count occurrences of each age range\n",
    "age_range_counts = []\n",
    "age_range_counts = unique_participants['Age Range'].value_counts().sort_index()\n",
    "\n",
    "# Calculate percentages\n",
    "age_range_percentages = (age_range_counts / total_participants) * 100\n",
    "\n",
    "# Display the results\n",
    "for age_range, count in age_range_counts.items():\n",
    "    percentage = age_range_percentages[age_range]\n",
    "    print(f\"{age_range} : {count} ({percentage:.2f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Smoking Status Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"Smoking Status\"\n",
    "unique_smoking_status = []\n",
    "unique_smoking_status = unique_participants['Smoking Status'].unique()\n",
    "# Print the unique items\n",
    "display(unique_smoking_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'Smoking Status' column\n",
    "smoking_status_counts = []\n",
    "smoking_status_counts = unique_participants['Smoking Status'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each ethnicity\n",
    "smoking_status_percentages = []\n",
    "smoking_status_percentages = (smoking_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "smoking_status_counts_with_percentages = []\n",
    "smoking_status_counts_with_percentages = smoking_status_counts.astype(str) + \" (\" + smoking_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'Smoking Status' column:\")\n",
    "display(smoking_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>BMI Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"BMI Range\"\n",
    "unique_BMI_status = []\n",
    "unique_BMI_status = unique_participants['BMI Range'].unique()\n",
    "# Print the unique items\n",
    "display(unique_BMI_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'BMI Range' column\n",
    "BMI_status_counts = []\n",
    "BMI_status_counts = unique_participants['BMI Range'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "BMI_status_percentages = []\n",
    "BMI_status_percentages = (BMI_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "BMI_status_counts_with_percentages = []\n",
    "BMI_status_counts_with_percentages = BMI_status_counts.astype(str) + \" (\" + BMI_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'BMI Range' column:\")\n",
    "display(BMI_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>IMD Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Display unique items under the column \"IMD_quintile\"\n",
    "unique_IMD_status = []\n",
    "unique_IMD_status = unique_participants['IMD_quintile'].unique()\n",
    "# Print the unique items\n",
    "display(unique_IMD_status)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Count occurrences of unique values in the 'IMD_quintile' column\n",
    "IMD_status_counts = []\n",
    "IMD_status_counts = unique_participants['IMD_quintile'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "IMD_status_percentages = []\n",
    "IMD_status_percentages = (IMD_status_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "IMD_status_counts_with_percentages = []\n",
    "IMD_status_counts_with_percentages = IMD_status_counts.astype(str) + \" (\" + IMD_status_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'IMD_quintile' column:\")\n",
    "display(IMD_status_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Age Specific Mortality Counts for Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls_heart_failure.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "# Count occurrences of unique values in the 'Alive / Dead' column\n",
    "total_alive_dead_counts = []\n",
    "total_alive_dead_counts = unique_participants['Alive / Dead'].value_counts()\n",
    "\n",
    "# Calculate the percentage \n",
    "total_alive_dead_percentages = []\n",
    "total_alive_dead_percentages = (total_alive_dead_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages\n",
    "total_alive_dead_counts_with_percentages = []\n",
    "total_alive_dead_counts_with_percentages = total_alive_dead_counts.astype(str) + \" (\" + total_alive_dead_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of unique values in the 'Alive / Dead' column:\")\n",
    "display(total_alive_dead_counts_with_percentages)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Assume the DataFrame is already loaded as All_ICD10_with_Diseases_Dates_Data\n",
    "\n",
    "# Define the age ranges\n",
    "bins = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = [\"30 - 40\", \"41 - 50\", \"51 - 60\", \"61 - 70\", \"71 - 80\", \"81 - 90\", \"91 - 100\"]\n",
    "\n",
    "\n",
    "# Total number of participants\n",
    "total_participants = []\n",
    "total_participants = 2441\n",
    "\n",
    "\n",
    "# Drop duplicate Participant ID rows to get unique participants\n",
    "unique_participants = []\n",
    "unique_participants = matched_controls.drop_duplicates(subset=['Participant ID'])\n",
    "\n",
    "# Separate the counts for 'Alive' and 'Dead' within each age range\n",
    "alive_counts = []\n",
    "dead_counts = []\n",
    "alive_counts = unique_participants[unique_participants['Alive / Dead'] == 'Alive']['Age Range'].value_counts().sort_index()\n",
    "dead_counts = unique_participants[unique_participants['Alive / Dead'] == 'Dead']['Age Range'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the percentages\n",
    "alive_percentages = []\n",
    "dead_percentages = []\n",
    "alive_percentages = (alive_counts / total_participants) * 100\n",
    "dead_percentages = (dead_counts / total_participants) * 100\n",
    "\n",
    "# Combine counts and percentages for 'Alive'\n",
    "alive_counts_with_percentages = alive_counts.astype(str) + \" (\" + alive_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "# Combine counts and percentages for 'Dead'\n",
    "dead_counts_with_percentages = []\n",
    "dead_counts_with_percentages = dead_counts.astype(str) + \" (\" + dead_percentages.round(2).astype(str) + \"%)\"\n",
    "\n",
    "# Display the counts and percentages for 'Alive'\n",
    "print(\"Counts and percentages for 'Alive' in each age range:\")\n",
    "display(alive_counts_with_percentages)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Display the counts and percentages for 'Dead'\n",
    "print(\"Counts and percentages for 'Dead' in each age range:\")\n",
    "display(dead_counts_with_percentages)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center> This code is for creating the Process Mining for Heart Failure Matched Control Cohorts Versus PH Cohort Process Mining**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Process Mining of Heart Failure Matched Control Cohort </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart Failure Matched Control Using ICD10 Codes **I50.0** and **I50.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "matched_controls = []\n",
    "matched_controls = pd.read_csv('Heart Failure matched Control Cohort Dataset.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_matched_controls = {}\n",
    "row_counts_matched_controls = {}\n",
    "nan_counts_matched_controls = {}\n",
    "empty_counts_matched_controls = {}\n",
    "prefer_not_to_say_counts_matched_controls = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_matched_controls in matched_controls.columns:\n",
    "    unique_count_matched_controls = matched_controls[column_matched_controls].nunique()\n",
    "    row_count_matched_controls = len(matched_controls[column_matched_controls])\n",
    "    nan_count_matched_controls = matched_controls[column_matched_controls].isna().sum()  # Count NaN values\n",
    "    empty_count_matched_controls = matched_controls[column_matched_controls].eq('').sum()  # Count empty string values\n",
    "    prefer_not_to_say_count_matched_controls = matched_controls[column_matched_controls].eq('Prefer not to answer').sum()  \n",
    "\n",
    "    unique_counts_matched_controls[column_matched_controls] = [unique_count_matched_controls]\n",
    "    row_counts_matched_controls[column_matched_controls] = [row_count_matched_controls]\n",
    "    nan_counts_matched_controls[column_matched_controls] = [nan_count_matched_controls]\n",
    "    empty_counts_matched_controls[column_matched_controls] = [empty_count_matched_controls]\n",
    "    prefer_not_to_say_counts_matched_controls[column_matched_controls] = [prefer_not_to_say_count_matched_controls]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_matched_control = []\n",
    "row_counts_matched_control = []\n",
    "nan_counts_matched_control = []\n",
    "empty_counts_matched_control = []\n",
    "prefer_not_to_say_counts_matched_control =[]\n",
    "\n",
    "unique_counts_matched_control = pd.DataFrame(unique_counts_matched_controls, index=['Unique Count'])\n",
    "row_counts_matched_control = pd.DataFrame(row_counts_matched_controls, index=['Row Count'])\n",
    "nan_counts_matched_control = pd.DataFrame(nan_counts_matched_controls, index=['NaN Count'])\n",
    "empty_counts_matched_control = pd.DataFrame(empty_counts_matched_controls, index=['Empty Count'])\n",
    "prefer_not_to_say_counts_matched_control = pd.DataFrame(prefer_not_to_say_counts_matched_controls, index=['Prefer not to answer'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_matched_controls = []\n",
    "result_matched_controls = pd.concat([unique_counts_matched_control, row_counts_matched_control, nan_counts_matched_control, empty_counts_matched_control,prefer_not_to_say_counts_matched_control])\n",
    "\n",
    "\n",
    "matched_controls_heart_failure = []\n",
    "matched_controls_heart_failure = matched_controls\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"matched_controls:\")\n",
    "display(result_matched_controls)\n",
    "print()\n",
    "print()\n",
    "display(matched_controls_heart_failure.head(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Extract unique Participant IDs\n",
    "unique_participant_ids = []\n",
    "unique_participant_ids = matched_controls_heart_failure['Participant ID'].unique()\n",
    "#unique_participant_ids = pd.DataFrame(unique_participant_ids)\n",
    "# Display the unique Participant IDs\n",
    "print(\"Unique Participant IDs:\")\n",
    "display(unique_participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Dataset_with_ICD10_and_Diseases_Names_and_Death_Records = []\n",
    "Dataset_with_ICD10_and_Diseases_Names_and_Death_Records = pd.read_csv('Dataset with ICD10 and Diseases Names and Death Records.csv')\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_Final_Dataset2 = {}\n",
    "row_counts_Final_Dataset2 = {}\n",
    "nan_counts_Final_Dataset2 = {}\n",
    "empty_counts_Final_Dataset2 = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_Final_Dataset2 in Dataset_with_ICD10_and_Diseases_Names_and_Death_Records.columns:\n",
    "    unique_count_Final_Dataset2 = Dataset_with_ICD10_and_Diseases_Names_and_Death_Records[column_Final_Dataset2].nunique()\n",
    "    row_count_Final_Dataset2 = len(Dataset_with_ICD10_and_Diseases_Names_and_Death_Records[column_Final_Dataset2])\n",
    "    nan_count_Final_Dataset2 = Dataset_with_ICD10_and_Diseases_Names_and_Death_Records[column_Final_Dataset2].isna().sum()  # Count NaN values\n",
    "    empty_count_Final_Dataset2 = Dataset_with_ICD10_and_Diseases_Names_and_Death_Records[column_Final_Dataset2].eq('').sum()  # Count empty string values\n",
    "\n",
    "    unique_counts_Final_Dataset2[column_Final_Dataset2] = [unique_count_Final_Dataset2]\n",
    "    row_counts_Final_Dataset2[column_Final_Dataset2] = [row_count_Final_Dataset2]\n",
    "    nan_counts_Final_Dataset2[column_Final_Dataset2] = [nan_count_Final_Dataset2]\n",
    "    empty_counts_Final_Dataset2[column_Final_Dataset2] = [empty_count_Final_Dataset2]\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_Final_Dataset_Record2 = []\n",
    "row_counts_Final_Dataset_Record2 = []\n",
    "nan_counts_Final_Dataset_Record2 = []\n",
    "empty_counts_Final_Dataset_Record2 = []\n",
    "\n",
    "unique_counts_Final_Dataset_Record2 = pd.DataFrame(unique_counts_Final_Dataset2, index=['Unique Count'])\n",
    "row_counts_Final_Dataset_Record2 = pd.DataFrame(row_counts_Final_Dataset2, index=['Row Count'])\n",
    "nan_counts_Final_Dataset_Record2 = pd.DataFrame(nan_counts_Final_Dataset2, index=['NaN Count'])\n",
    "empty_counts_Final_Dataset_Record2 = pd.DataFrame(empty_counts_Final_Dataset2, index=['Empty Count'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_Final_Dataset2 = []\n",
    "result_Final_Dataset2 = pd.concat([unique_counts_Final_Dataset_Record2, row_counts_Final_Dataset_Record2, nan_counts_Final_Dataset_Record2, empty_counts_Final_Dataset_Record2])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"Dataset_with_ICD10_and_Diseases_Names_and_Death_Records:\")\n",
    "print()\n",
    "display(result_Final_Dataset2)\n",
    "print()\n",
    "print()\n",
    "Dataset_with_ICD10_and_Diseases_Names_and_Death_Records.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Extract Heart Failure Patients Datafrom the Main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "heart_failure_Matched_cohort_with_Comorbidities = Dataset_with_ICD10_and_Diseases_Names_and_Death_Records[\n",
    "    Dataset_with_ICD10_and_Diseases_Names_and_Death_Records['Participant ID'].isin(unique_participant_ids)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_heart_failure_Matched_cohort_with_Comorbidities in heart_failure_Matched_cohort_with_Comorbidities.columns:\n",
    "    unique_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].nunique()\n",
    "    row_count_heart_failure_Matched_cohort_with_Comorbidities = len(heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities])\n",
    "    nan_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].isna().sum()  # Count NaN values\n",
    "    empty_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].eq('').sum()  # Count empty string values\n",
    "\n",
    "    unique_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [unique_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    row_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [row_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    nan_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [nan_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    empty_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [empty_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(unique_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Unique Count'])\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(row_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Row Count'])\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(nan_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['NaN Count'])\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(empty_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Empty Count'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = pd.concat([unique_counts_heart_failure_Matched_cohort_with_Comorbidities2, row_counts_heart_failure_Matched_cohort_with_Comorbidities2, nan_counts_heart_failure_Matched_cohort_with_Comorbidities2, empty_counts_heart_failure_Matched_cohort_with_Comorbidities2])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "\n",
    "display(result_heart_failure_Matched_cohort_with_Comorbidities)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', None)  # Adjust as needed to see all rows if it's a large output\n",
    "display(heart_failure_Matched_cohort_with_Comorbidities.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> To check that this is Heart Failure Matched Control Cohort with Non-PH rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target values to check\n",
    "target_icd10_values = []\n",
    "target_icd10_values = ['I27.0', 'I27.2', 'I27.9']\n",
    "\n",
    "# Filter the DataFrame based on whether 'Combined ICD10 Codes' contains any of the target values\n",
    "check = []\n",
    "check = heart_failure_Matched_cohort_with_Comorbidities[\n",
    "    heart_failure_Matched_cohort_with_Comorbidities['Combined ICD10 Codes'].isin(target_icd10_values)\n",
    "]\n",
    "\n",
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> to check that this is right Heart Failure Control Cohort with Comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the heart_failure ICD10 codes to check\n",
    "heart_failure_icd10_codes = []\n",
    "heart_failure_icd10_codes = ['I50.0', 'I50.1']\n",
    "\n",
    "# Filter the DataFrame to find participants who have at least one of the heart_failure ICD10 codes\n",
    "participants_with_heart_failure = []\n",
    "participants_with_heart_failure = heart_failure_Matched_cohort_with_Comorbidities[\n",
    "    heart_failure_Matched_cohort_with_Comorbidities['Combined ICD10 Codes'].isin(heart_failure_icd10_codes)\n",
    "]['Participant ID'].unique()\n",
    "\n",
    "# Check if all participants in the DataFrame have a heart_failure code\n",
    "all_have_heart_failure  = []\n",
    "all_have_heart_failure = set(heart_failure_Matched_cohort_with_Comorbidities['Participant ID'].unique()).issubset(set(participants_with_heart_failure))\n",
    "\n",
    "# Display the result\n",
    "if all_have_heart_failure:\n",
    "    print(\"All participants have at least one of the specified heart_failure ICD10 codes.\")\n",
    "else:\n",
    "    print(\"Not all participants have one of the specified heart_failure ICD10 codes.\")\n",
    "\n",
    "# Optionally, display the IDs of participants who do not have any of the COPD codes\n",
    "participants_without_heart_failure = []\n",
    "participants_without_heart_failure = set(heart_failure_Matched_cohort_with_Comorbidities['Participant ID'].unique()) - set(participants_with_heart_failure)\n",
    "participants_without_heart_failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Save \"Heart Failure Control with Comorbidities Cohort Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Heart Failure Matched cohort with Comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#heart_failure_Matched_cohort_with_Comorbidities.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Read the File \"Heart Failure Matched cohort with Comorbidities.csv\" </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "heart_failure_Matched_cohort_with_Comorbidities = pd.read_csv('Heart Failure Matched cohort with Comorbidities.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_heart_failure_Matched_cohort_with_Comorbidities in heart_failure_Matched_cohort_with_Comorbidities.columns:\n",
    "    unique_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].nunique()\n",
    "    row_count_heart_failure_Matched_cohort_with_Comorbidities = len(heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities])\n",
    "    nan_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].isna().sum()  # Count NaN values\n",
    "    empty_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].eq('').sum()  # Count empty string values\n",
    "\n",
    "    unique_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [unique_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    row_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [row_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    nan_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [nan_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    empty_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [empty_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(unique_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Unique Count'])\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(row_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Row Count'])\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(nan_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['NaN Count'])\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(empty_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Empty Count'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = pd.concat([unique_counts_heart_failure_Matched_cohort_with_Comorbidities2, row_counts_heart_failure_Matched_cohort_with_Comorbidities2, nan_counts_heart_failure_Matched_cohort_with_Comorbidities2, empty_counts_heart_failure_Matched_cohort_with_Comorbidities2])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "\n",
    "display(result_heart_failure_Matched_cohort_with_Comorbidities)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', None)  # Adjust as needed to see all rows if it's a large output\n",
    "display(heart_failure_Matched_cohort_with_Comorbidities.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Drop the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns by name\n",
    "heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities.drop(columns=['Death Cause Diseases','Death Cause Disease ICD10 Codes'])\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Create \"Disease Chapters\" and \"Diseases Subchapters\" Variables in the Dataset </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_icd10(icd10_code):\n",
    "    if 'A00.0' <= icd10_code <= 'A09.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A00-A09 Intestinal infectious diseases'\n",
    "    elif 'A15.0' <= icd10_code <= 'A19.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A15-A19 Tuberculosis'\n",
    "    elif 'A20.0' <= icd10_code <= 'A28.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A20-A28 Certain zoonotic bacterial diseases'\n",
    "    elif 'A30.0' <= icd10_code <= 'A49.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A30-A49 Other bacterial diseases'\n",
    "    elif 'A50.0' <= icd10_code <= 'A64.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A50-A64 Infections with a predominantly sexual mode of transmission'\n",
    "    elif 'A65.0' <= icd10_code <= 'A69.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A65-A69 Other spirochaetal diseases'\n",
    "    elif 'A70.0' <= icd10_code <= 'A74.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A70-A74 Other diseases caused by chlamydiae'\n",
    "    elif 'A70' <= icd10_code <= 'A74':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A70-A74 Other diseases caused by chlamydiae'\n",
    "    elif 'A75.0' <= icd10_code <= 'A79.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A75-A79 Rickettsioses'\n",
    "    elif 'A80.0' <= icd10_code <= 'A89.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A80-A89 Viral infections of the central nervous system'\n",
    "    elif 'A90' <= icd10_code <= 'A90':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A80-A89 Viral infections of the central nervous system' \n",
    "    elif 'A92.0' <= icd10_code <= 'A99.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'A92-A99 Arthropod-borne viral fevers and viral haemorrhagic fevers'\n",
    "    elif 'B00.0' <= icd10_code <= 'B09.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B00-B09 Viral infections characterized by skin and mucous membrane lesions'\n",
    "    elif 'B15.0' <= icd10_code <= 'B19.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B15-B19 Viral hepatitis'\n",
    "    elif 'B20.0' <= icd10_code <= 'B24.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B20-B24 Human immunodeficiency virus [HIV] disease'\n",
    "    elif 'B25.0' <= icd10_code <= 'B34.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B25-B34 Other viral diseases'\n",
    "    elif 'B35.0' <= icd10_code <= 'B49.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B35-B49 Mycoses'\n",
    "    elif 'B50.0' <= icd10_code <= 'B64.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B50-B64 Protozoal diseases'\n",
    "    elif 'B65.0' <= icd10_code <= 'B83.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B65-B83 Helminthiases'\n",
    "    elif 'B85.0' <= icd10_code <= 'B89.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B85-B89 Pediculosis, acariasis and other infestations'\n",
    "    elif 'B90.0' <= icd10_code <= 'B94.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B90-B94 Sequelae of infectious and parasitic diseases'\n",
    "    elif 'B95.0' <= icd10_code <= 'B98.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B95-B98 Bacterial, viral and other infectious agents'\n",
    "    elif 'B99.0' <= icd10_code <= 'B99.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B99-B99 Other infectious diseases'\n",
    "    elif 'B99.0' <= icd10_code <= 'B99.9':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B99-B99 Other infectious diseases'\n",
    "    elif 'B99' <= icd10_code <= 'B99':\n",
    "        return 'Chapter I Certain infectious and parasitic diseases', 'B99-B99 Other infectious diseases'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'C00.0' <= icd10_code <= 'C14.9':\n",
    "        return 'Chapter II Neoplasms', 'C00-C14 Malignant neoplasms of lip, oral cavity and pharynx'\n",
    "    elif 'C15.0' <= icd10_code <= 'C26.9':\n",
    "        return 'Chapter II Neoplasms', 'C15-C26 Malignant neoplasms of digestive organs'\n",
    "    elif 'C30.0' <= icd10_code <= 'C39.9':\n",
    "        return 'Chapter II Neoplasms', 'C30-C39 Malignant neoplasms of respiratory and intrathoracic organs'\n",
    "    elif 'C40.0' <= icd10_code <= 'C41.9':\n",
    "        return 'Chapter II Neoplasms', 'C40-C41 Malignant neoplasms of bone and articular cartilage'\n",
    "    elif 'C43.0' <= icd10_code <= 'C44.9':\n",
    "        return 'Chapter II Neoplasms', 'C43-C44 Melanoma and other malignant neoplasms of skin'\n",
    "    elif 'C45.0' <= icd10_code <= 'C49.9':\n",
    "        return 'Chapter II Neoplasms', 'C45-C49 Malignant neoplasms of mesothelial and soft tissue'\n",
    "    elif 'C50.0' <= icd10_code <= 'C50.9':\n",
    "        return 'Chapter II Neoplasms', 'C50-C50 Malignant neoplasm of breast'\n",
    "    elif 'C51.0' <= icd10_code <= 'C58.9':\n",
    "        return 'Chapter II Neoplasms', 'C51-C58 Malignant neoplasms of female genital organs'\n",
    "    elif 'C60.0' <= icd10_code <= 'C63.9':\n",
    "        return 'Chapter II Neoplasms', 'C60-C63 Malignant neoplasms of male genital organs'\n",
    "    elif 'C64.0' <= icd10_code <= 'C68.9':\n",
    "        return 'Chapter II Neoplasms', 'C64-C68 Malignant neoplasms of urinary tract'\n",
    "    elif 'C64' <= icd10_code <= 'C68':\n",
    "        return 'Chapter II Neoplasms', 'C64-C68 Malignant neoplasms of urinary tract'\n",
    "    elif 'C69.0' <= icd10_code <= 'C72.9':\n",
    "        return 'Chapter II Neoplasms', 'C69-C72 Malignant neoplasms of eye, brain and other parts of central nervous system'\n",
    "    elif 'C73.0' <= icd10_code <= 'C75.9':\n",
    "        return 'Chapter II Neoplasms', 'C73-C75 Malignant neoplasms of thyroid and other endocrine glands'\n",
    "    elif 'C73' <= icd10_code <= 'C75':\n",
    "        return 'Chapter II Neoplasms', 'C73-C75 Malignant neoplasms of thyroid and other endocrine glands'\n",
    "    elif 'C76.0' <= icd10_code <= 'C80.9':\n",
    "        return 'Chapter II Neoplasms', 'C76-C80 Malignant neoplasms of ill-defined, secondary and unspecified sites'\n",
    "    elif 'C81.0' <= icd10_code <= 'C96.9':\n",
    "        return 'Chapter II Neoplasms', 'C81-C96 Malignant neoplasms, stated or presumed to be primary, of lymphoid, haematopoietic and related tissue'\n",
    "    elif 'C97.0' <= icd10_code <= 'C97.9':\n",
    "        return 'Chapter II Neoplasms', 'C97-C97 Malignant neoplasms of independent (primary) multiple sites'\n",
    "    elif 'C97' <= icd10_code <= 'C97':\n",
    "        return 'Chapter II Neoplasms', 'C97-C97 Malignant neoplasms of independent (primary) multiple sites'\n",
    "    elif 'D00.0' <= icd10_code <= 'D09.9':\n",
    "        return 'Chapter II Neoplasms', 'D00-D09 In situ neoplasms'\n",
    "    elif 'D10.0' <= icd10_code <= 'D36.9':\n",
    "        return 'Chapter II Neoplasms', 'D10-D36 Benign neoplasms'\n",
    "    elif 'D37.0' <= icd10_code <= 'D48.9':\n",
    "        return 'Chapter II Neoplasms', 'D37-D48 Neoplasms of uncertain or unknown behaviour'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'D50.0' <= icd10_code <= 'D53.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D50-D53 Nutritional anaemias'\n",
    "    elif 'D55.0' <= icd10_code <= 'D59.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D55-D59 Haemolytic anaemias'\n",
    "    elif 'D60.0' <= icd10_code <= 'D64.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D60-D64 Aplastic and other anaemias'\n",
    "    elif 'D65' <= icd10_code <= 'D65':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D65-D69 Coagulation defects, purpura and other haemorrhagic conditions'\n",
    "    elif 'D65.0' <= icd10_code <= 'D69.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D65-D69 Coagulation defects, purpura and other haemorrhagic conditions'\n",
    "    elif 'D70.0' <= icd10_code <= 'D77.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D70-D77 Other diseases of blood and blood-forming organs'\n",
    "    elif 'D70' <= icd10_code <= 'D77':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D70-D77 Other diseases of blood and blood-forming organs'\n",
    "    elif 'D80.0' <= icd10_code <= 'D89.9':\n",
    "        return 'Chapter III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism', 'D80-D89 Certain disorders involving the immune mechanism'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'E00.0' <= icd10_code <= 'E07.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E00-E07 Disorders of thyroid gland'\n",
    "    elif 'E10.0' <= icd10_code <= 'E14.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E10-E14 Diabetes mellitus'\n",
    "    elif 'E15.0' <= icd10_code <= 'E16.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E15-E16 Other disorders of glucose regulation and pancreatic internal secretion'\n",
    "    elif 'E20.0' <= icd10_code <= 'E35.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E20-E35 Disorders of other endocrine glands'\n",
    "    elif 'E40.0' <= icd10_code <= 'E46.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E40-E46 Malnutrition'\n",
    "    elif 'E50.0' <= icd10_code <= 'E64.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E50-E64 Other nutritional deficiencies'\n",
    "    elif 'E65.0' <= icd10_code <= 'E68.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E65-E68 Obesity and other hyperalimentation'\n",
    "    elif 'E65' <= icd10_code <= 'E68':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E65-E68 Obesity and other hyperalimentation'\n",
    "    elif 'E70.0' <= icd10_code <= 'E90.9':\n",
    "        return 'Chapter IV Endocrine, nutritional and metabolic diseases', 'E70-E90 Metabolic disorders'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'F00.0' <= icd10_code <= 'F09.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F00-F09 Organic, including symptomatic, mental disorders'\n",
    "    elif 'F10.0' <= icd10_code <= 'F19.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F10-F19 Mental and behavioural disorders due to psychoactive substance use'\n",
    "    elif 'F20.0' <= icd10_code <= 'F29.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F20-F29 Schizophrenia, schizotypal and delusional disorders'\n",
    "    elif 'F30.0' <= icd10_code <= 'F39.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F30-F39 Mood [affective] disorders'\n",
    "    elif 'F40.0' <= icd10_code <= 'F48.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F40-F48 Neurotic, stress-related and somatoform disorders'\n",
    "    elif 'F50.0' <= icd10_code <= 'F59.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F50-F59 Behavioural syndromes associated with physiological disturbances and physical factors'\n",
    "    elif 'F60.0' <= icd10_code <= 'F69.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F60-F69 Disorders of adult personality and behaviour'\n",
    "    elif 'F70.0' <= icd10_code <= 'F79.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F70-F79 Mental retardation'\n",
    "    elif 'F80.0' <= icd10_code <= 'F89.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F80-F89 Disorders of psychological development'\n",
    "    elif 'F90.0' <= icd10_code <= 'F98.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F90-F98 Behavioural and emotional disorders with onset usually occurring in childhood and adolescence'\n",
    "    elif 'F99.0' <= icd10_code <= 'F99.9':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F99-F99 Unspecified mental disorder'\n",
    "    elif 'F99' <= icd10_code <= 'F99':\n",
    "        return 'Chapter V Mental and behavioural disorders', 'F99-F99 Unspecified mental disorder'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'G00.0' <= icd10_code <= 'G09.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G00-G09 Inflammatory diseases of the central nervous system'\n",
    "    elif 'G10.0' <= icd10_code <= 'G14.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G10-G14 Systemic atrophies primarily affecting the central nervous system'\n",
    "    elif 'G10' <= icd10_code <= 'G10':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G10-G14 Systemic atrophies primarily affecting the central nervous system'\n",
    "    elif 'G20.0' <= icd10_code <= 'G26.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G20-G26 Extrapyramidal and movement disorders'\n",
    "    elif 'G20' <= icd10_code <= 'G26':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G20-G26 Extrapyramidal and movement disorders'\n",
    "    elif 'G30.0' <= icd10_code <= 'G32.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G30-G32 Other degenerative diseases of the nervous system'\n",
    "    elif 'G35.0' <= icd10_code <= 'G37.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G35-G37 Demyelinating diseases of the central nervous system'\n",
    "    elif 'G35' <= icd10_code <= 'G37':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G35-G37 Demyelinating diseases of the central nervous system'\n",
    "    elif 'G40.0' <= icd10_code <= 'G47.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G40-G47 Episodic and paroxysmal disorders'\n",
    "    elif 'G50.0' <= icd10_code <= 'G59.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G50-G59 Nerve, nerve root and plexus disorders'\n",
    "    elif 'G60.0' <= icd10_code <= 'G64.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G60-G64 Polyneuropathies and other disorders of the peripheral nervous system'\n",
    "    elif 'G70.0' <= icd10_code <= 'G73.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G70-G73 Diseases of myoneural junction and muscle'\n",
    "    elif 'G80.0' <= icd10_code <= 'G83.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G80-G83 Cerebral palsy and other paralytic syndromes'\n",
    "    elif 'G90.0' <= icd10_code <= 'G99.9':\n",
    "        return 'Chapter VI Diseases of the nervous system', 'G90-G99 Other disorders of the nervous system'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'H00.0' <= icd10_code <= 'H06.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H00-H06 Disorders of eyelid, lacrimal system and orbit'\n",
    "    elif 'H10.0' <= icd10_code <= 'H13.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H10-H13 Disorders of conjunctiva'\n",
    "    elif 'H15.0' <= icd10_code <= 'H22.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H15-H22 Disorders of sclera, cornea, iris and ciliary body'\n",
    "    elif 'H25.0' <= icd10_code <= 'H28.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H25-H28 Disorders of lens'\n",
    "    elif 'H30.0' <= icd10_code <= 'H36.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H30-H36 Disorders of choroid and retina'\n",
    "    elif 'H40.0' <= icd10_code <= 'H42.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H40-H42 Glaucoma'\n",
    "    elif 'H43.0' <= icd10_code <= 'H45.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H43-H45 Disorders of vitreous body and globe'\n",
    "    elif 'H46.0' <= icd10_code <= 'H48.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H46-H48 Disorders of optic nerve and visual pathways'\n",
    "    elif 'H49.0' <= icd10_code <= 'H52.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H49-H52 Disorders of ocular muscles, binocular movement, accommodation and refraction'\n",
    "    elif 'H53.0' <= icd10_code <= 'H54.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H53-H54 Visual disturbances and blindness'\n",
    "    elif 'H55.0' <= icd10_code <= 'H59.9':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H55-H59 Other disorders of eye and adnexa'\n",
    "    elif 'H55' <= icd10_code <= 'H59':\n",
    "        return 'Chapter VII Diseases of the eye and adnexa', 'H55-H59 Other disorders of eye and adnexa'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'H60.0' <= icd10_code <= 'H62.9':\n",
    "        return 'Chapter VIII Diseases of the ear and mastoid process', 'H60-H62 Diseases of external ear'\n",
    "    elif 'H46' <= icd10_code <= 'H46':\n",
    "        return 'Chapter VIII Diseases of the ear and mastoid process', 'H46-H48 Disorders of optic nerve and visual pathways'\n",
    "    elif 'H65.0' <= icd10_code <= 'H75.9':\n",
    "        return 'Chapter VIII Diseases of the ear and mastoid process', 'H65-H75 Diseases of middle ear and mastoid'\n",
    "    elif 'H80.0' <= icd10_code <= 'H83.9':\n",
    "        return 'Chapter VIII Diseases of the ear and mastoid process', 'H80-H83 Diseases of inner ear'\n",
    "    elif 'H90.0' <= icd10_code <= 'H95.9':\n",
    "        return 'Chapter VIII Diseases of the ear and mastoid process', 'H90-H95 Other disorders of ear'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'I00.0' <= icd10_code <= 'I02.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I00-I02 Acute rheumatic fever'\n",
    "    elif 'I00' <= icd10_code <= 'I02':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I00-I02 Acute rheumatic fever'\n",
    "    elif 'I05.0' <= icd10_code <= 'I09.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I05-I09 Chronic rheumatic heart diseases'\n",
    "    elif 'I10.0' <= icd10_code <= 'I15.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I10-I15 Hypertensive diseases'\n",
    "    elif 'I10' <= icd10_code <= 'I15':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I10-I15 Hypertensive diseases'\n",
    "    elif 'I20.0' <= icd10_code <= 'I25.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I20-I25 Ischaemic heart diseases'\n",
    "    elif 'I26.0' <= icd10_code <= 'I28.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I26-I28 Pulmonary heart disease and diseases of pulmonary circulation'\n",
    "    elif 'I30.0' <= icd10_code <= 'I52.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I30-I52 Other forms of heart disease'\n",
    "    elif 'I60.0' <= icd10_code <= 'I69.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I60-I69 Cerebrovascular diseases'\n",
    "    elif 'I70.0' <= icd10_code <= 'I79.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I70-I79 Diseases of arteries, arterioles and capillaries'\n",
    "    elif 'I80.0' <= icd10_code <= 'I89.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I80-I89 Diseases of veins, lymphatic vessels and lymph nodes, not elsewhere classified'\n",
    "    elif 'I95.0' <= icd10_code <= 'I99.9':\n",
    "        return 'Chapter IX Diseases of the circulatory system', 'I95-I99 Other and unspecified disorders of the circulatory system'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'J00.0' <= icd10_code <= 'J06.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J00-J06 Acute upper respiratory infections'\n",
    "    elif 'J00' <= icd10_code <= 'J06':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J00-J06 Acute upper respiratory infections'\n",
    "    elif 'J09.0' <= icd10_code <= 'J18.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J09-J18 Influenza and pneumonia'\n",
    "    elif 'J09' <= icd10_code <= 'J18':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J09-J18 Influenza and pneumonia'\n",
    "    elif 'J20.0' <= icd10_code <= 'J22.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J20-J22 Other acute lower respiratory infections'\n",
    "    elif 'J30.0' <= icd10_code <= 'J39.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J30-J39 Other diseases of upper respiratory tract'\n",
    "    elif 'J40.0' <= icd10_code <= 'J47.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J40-J47 Chronic lower respiratory diseases'\n",
    "    elif 'J40' <= icd10_code <= 'J47':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J40-J47 Chronic lower respiratory diseases'\n",
    "    elif 'J60.0' <= icd10_code <= 'J70.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J60-J70 Lung diseases due to external agents'\n",
    "    elif 'J60' <= icd10_code <= 'J60':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J60-J70 Lung diseases due to external agents'\n",
    "    elif 'J80.0' <= icd10_code <= 'J84.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J80-J84 Other respiratory diseases principally affecting the interstitium'\n",
    "    elif 'J80' <= icd10_code <= 'J84':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J80-J84 Other respiratory diseases principally affecting the interstitium'\n",
    "    elif 'J85.0' <= icd10_code <= 'J86.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J85-J86 Suppurative and necrotic conditions of lower respiratory tract'\n",
    "    elif 'J90' <= icd10_code <= 'J94':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J90-J94 Other diseases of pleura'\n",
    "    elif 'J90.0' <= icd10_code <= 'J94.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J90-J94 Other diseases of pleura'\n",
    "    elif 'J95.0' <= icd10_code <= 'J99.9':\n",
    "        return 'Chapter X Diseases of the respiratory system', 'J95-J99 Other diseases of the respiratory system'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'K00.0' <= icd10_code <= 'K14.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K00-K14 Diseases of oral cavity, salivary glands and jaws'\n",
    "    elif 'K20.0' <= icd10_code <= 'K31.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K20-K31 Diseases of oesophagus, stomach and duodenum'\n",
    "    elif 'K20' <= icd10_code <= 'K31':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K20-K31 Diseases of oesophagus, stomach and duodenum'\n",
    "    elif 'K35.0' <= icd10_code <= 'K38.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K35-K38 Diseases of appendix'\n",
    "    elif 'K40.0' <= icd10_code <= 'K46.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K40-K46 Hernia'\n",
    "    elif 'K50.0' <= icd10_code <= 'K52.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K50-K52 Noninfective enteritis and colitis'\n",
    "    elif 'K55.0' <= icd10_code <= 'K64.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K55-K64 Other diseases of intestines'\n",
    "    elif 'K65.0' <= icd10_code <= 'K67.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K65-K67 Diseases of peritoneum'\n",
    "    elif 'K70.0' <= icd10_code <= 'K77.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K70-K77 Diseases of liver'\n",
    "    elif 'K80.0' <= icd10_code <= 'K87.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K80-K87 Disorders of gallbladder, biliary tract and pancreas'\n",
    "    elif 'K90.0' <= icd10_code <= 'K93.9':\n",
    "        return 'Chapter XI Diseases of the digestive system', 'K90-K93 Other diseases of the digestive system'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'L00.0' <= icd10_code <= 'L08.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L00-L08 Infections of the skin and subcutaneous tissue'\n",
    "    elif 'L10.0' <= icd10_code <= 'L14.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L10-L14 Bullous disorders'\n",
    "    elif 'L20.0' <= icd10_code <= 'L30.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L20-L30 Dermatitis and eczema'\n",
    "    elif 'L40.0' <= icd10_code <= 'L45.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L40-L45 Papulosquamous disorders'\n",
    "    elif 'L50.0' <= icd10_code <= 'L54.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L50-L54 Urticaria and erythema'\n",
    "    elif 'L55.0' <= icd10_code <= 'L59.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L55-L59 Radiation-related disorders of the skin and subcutaneous tissue'\n",
    "    elif 'L60.0' <= icd10_code <= 'L75.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L60-L75 Disorders of skin appendages'\n",
    "    elif 'L80.0' <= icd10_code <= 'L99.9':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L80-L99 Other disorders of the skin and subcutaneous tissue'\n",
    "    elif 'L80' <= icd10_code <= 'L99':\n",
    "        return 'Chapter XII Diseases of the skin and subcutaneous tissue', 'L80-L99 Other disorders of the skin and subcutaneous tissue'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'M00.0' <= icd10_code <= 'M03.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M00-M03 Infectious arthropathies'\n",
    "    elif 'M05.0' <= icd10_code <= 'M14.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M05-M14 Inflammatory polyarthropathies'\n",
    "    elif 'M15.0' <= icd10_code <= 'M19.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M15-M19 Arthrosis'\n",
    "    elif 'M20.0' <= icd10_code <= 'M25.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M20-M25 Other joint disorders'\n",
    "    elif 'M30.0' <= icd10_code <= 'M36.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M30-M36 Systemic connective tissue disorders'\n",
    "    elif 'M40.0' <= icd10_code <= 'M43.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M40-M43 Deforming dorsopathies'\n",
    "    elif 'M43.99' <= icd10_code <= 'M43.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M40-M43 Deforming dorsopathies'\n",
    "    elif 'M45.0' <= icd10_code <= 'M49.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M45-M49 Spondylopathies'\n",
    "    elif 'M45' <= icd10_code <= 'M49':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M45-M49 Spondylopathies'\n",
    "    elif 'M50.0' <= icd10_code <= 'M54.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M50-M54 Other dorsopathies'\n",
    "    elif 'M60.0' <= icd10_code <= 'M63.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M60-M63 Disorders of muscles'\n",
    "    elif 'M65.0' <= icd10_code <= 'M68.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M65-M68 Disorders of synovium and tendon'\n",
    "    elif 'M70.0' <= icd10_code <= 'M79.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M70-M79 Other soft tissue disorders'\n",
    "    elif 'M80.0' <= icd10_code <= 'M85.99':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M80-M85 Disorders of bone density and structure'\n",
    "    elif 'M86.0' <= icd10_code <= 'M90.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M86-M90 Other osteopathies'\n",
    "    elif 'M91.0' <= icd10_code <= 'M94.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M91-M94 Chondropathies'\n",
    "    elif 'M95.0' <= icd10_code <= 'M99.9':\n",
    "        return 'Chapter XIII Diseases of the musculoskeletal system and connective tissue', 'M95-M99 Other disorders of the musculoskeletal system and connective tissue'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'N00.0' <= icd10_code <= 'N08.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N00-N08 Glomerular diseases'\n",
    "    elif 'N10.0' <= icd10_code <= 'N16.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N10-N16 Renal tubulo-interstitial diseases'\n",
    "    elif 'N10' <= icd10_code <= 'N16':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N10-N16 Renal tubulo-interstitial diseases'\n",
    "    elif 'N17.0' <= icd10_code <= 'N19.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N17-N19 Renal failure'\n",
    "    elif 'N20.0' <= icd10_code <= 'N23.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N20-N23 Urolithiasis'\n",
    "    elif 'N25.0' <= icd10_code <= 'N29.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N25-N29 Other disorders of kidney and ureter'\n",
    "    elif 'N30.0' <= icd10_code <= 'N39.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N30-N39 Other diseases of urinary system'\n",
    "    elif 'N40' <= icd10_code <= 'N51':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N40-N51 Diseases of male genital organs'\n",
    "    elif 'N40.0' <= icd10_code <= 'N51.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N40-N51 Diseases of male genital organs'\n",
    "    elif 'N60.0' <= icd10_code <= 'N64.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N60-N64 Disorders of breast'\n",
    "    elif 'N70.0' <= icd10_code <= 'N77.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N70-N77 Inflammatory diseases of female pelvic organs'\n",
    "    elif 'N80.0' <= icd10_code <= 'N98.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N80-N98 Noninflammatory disorders of female genital tract'\n",
    "    elif 'N99.0' <= icd10_code <= 'N99.9':\n",
    "        return 'Chapter XIV Diseases of the genitourinary system', 'N99-N99 Other disorders of the genitourinary system'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'O00.0' <= icd10_code <= 'O08.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O00-O08 Pregnancy with abortive outcome'\n",
    "    elif 'O10.0' <= icd10_code <= 'O16.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O10-O16 Oedema, proteinuria and hypertensive disorders in pregnancy, childbirth and the puerperium'\n",
    "    elif 'O20.0' <= icd10_code <= 'O29.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O20-O29 Other maternal disorders predominantly related to pregnancy'\n",
    "    elif 'O30.0' <= icd10_code <= 'O48.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O30-O48 Maternal care related to the fetus and amniotic cavity and possible delivery problems'\n",
    "    elif 'O60.0' <= icd10_code <= 'O75.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O60-O75 Complications of labour and delivery'\n",
    "    elif 'O60' <= icd10_code <= 'O60':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O60-O75 Complications of labour and delivery'\n",
    "    elif 'O80.0' <= icd10_code <= 'O84.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O80-O84 Delivery'\n",
    "    elif 'O85.0' <= icd10_code <= 'O92.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O85-O92 Complications predominantly related to the puerperium'\n",
    "    elif 'O85' <= icd10_code <= 'O85':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O85-O92 Complications predominantly related to the puerperium'\n",
    "    elif 'O94.0' <= icd10_code <= 'O99.9':\n",
    "        return 'Chapter XV Pregnancy, childbirth and the puerperium', 'O94-O99 Other obstetric conditions, not elsewhere classified'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'P00.0' <= icd10_code <= 'P04.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P00-P04 Fetus and newborn affected by maternal factors and by complications of pregnancy, labour and delivery'\n",
    "    elif 'P05.0' <= icd10_code <= 'P08.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P05-P08 Disorders related to length of gestation and fetal growth'\n",
    "    elif 'P10.0' <= icd10_code <= 'P15.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P10-P15 Birth trauma'\n",
    "    elif 'P20.0' <= icd10_code <= 'P29.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P20-P29 Respiratory and cardiovascular disorders specific to the perinatal period'\n",
    "    elif 'P35.0' <= icd10_code <= 'P39.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P35-P39 Infections specific to the perinatal period'\n",
    "    elif 'P50.0' <= icd10_code <= 'P61.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P50-P61 Haemorrhagic and haematological disorders of fetus and newborn'\n",
    "    elif 'P80.0' <= icd10_code <= 'P83.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P80-P83 Conditions involving the integument and temperature regulation of fetus and newborn'\n",
    "    elif 'P90.0' <= icd10_code <= 'P96.9':\n",
    "        return 'Chapter XVI Certain conditions originating in the perinatal period', 'P90-P96 Other disorders originating in the perinatal period'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'Q00.0' <= icd10_code <= 'Q07.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q00-Q07 Congenital malformations of the nervous system'\n",
    "    elif 'Q10.0' <= icd10_code <= 'Q18.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q10-Q18 Congenital malformations of eye, ear, face and neck'\n",
    "    elif 'Q20.0' <= icd10_code <= 'Q28.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q20-Q28 Congenital malformations of the circulatory system'\n",
    "    elif 'Q30.0' <= icd10_code <= 'Q34.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q30-Q34 Congenital malformations of the respiratory system'\n",
    "    elif 'Q35.0' <= icd10_code <= 'Q37.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q35-Q37 Cleft lip and cleft palate'\n",
    "    elif 'Q38.0' <= icd10_code <= 'Q45.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q38-Q45 Other congenital malformations of the digestive system'\n",
    "    elif 'Q50.0' <= icd10_code <= 'Q56.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q50-Q56 Congenital malformations of genital organs'\n",
    "    elif 'Q60.0' <= icd10_code <= 'Q64.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q60-Q64 Congenital malformations of the urinary system'\n",
    "    elif 'Q65.0' <= icd10_code <= 'Q79.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q65-Q79 Congenital malformations and deformations of the musculoskeletal system'\n",
    "    elif 'Q80.0' <= icd10_code <= 'Q89.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q80-Q89 Other congenital malformations'\n",
    "    elif 'Q90.0' <= icd10_code <= 'Q99.9':\n",
    "        return 'Chapter XVII Congenital malformations, deformations and chromosomal abnormalities', 'Q90-Q99 Chromosomal abnormalities, not elsewhere classified'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'R00.0' <= icd10_code <= 'R09.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R00-R09 Symptoms and signs involving the circulatory and respiratory systems'\n",
    "    elif 'R10.0' <= icd10_code <= 'R19.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R10-R19 Symptoms and signs involving the digestive system and abdomen'\n",
    "    elif 'R20.0' <= icd10_code <= 'R23.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R20-R23 Symptoms and signs involving the skin and subcutaneous tissue'\n",
    "    elif 'R25.0' <= icd10_code <= 'R29.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R25-R29 Symptoms and signs involving the nervous and musculoskeletal systems'\n",
    "    elif 'R30.0' <= icd10_code <= 'R39.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R30-R39 Symptoms and signs involving the urinary system'\n",
    "    elif 'R40.0' <= icd10_code <= 'R46.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R40-R46 Symptoms and signs involving cognition, perception, emotional state and behaviour'\n",
    "    elif 'R47.0' <= icd10_code <= 'R49.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R47-R49 Symptoms and signs involving speech and voice'\n",
    "    elif 'R50.0' <= icd10_code <= 'R69.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R50-R69 General symptoms and signs'\n",
    "    elif 'R70.0' <= icd10_code <= 'R79.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R70-R79 Abnormal findings on examination of blood, without diagnosis'\n",
    "    elif 'R80' <= icd10_code <= 'R82':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R80-R82 Abnormal findings on examination of urine, without diagnosis'\n",
    "    elif 'R80.0' <= icd10_code <= 'R82.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R80-R82 Abnormal findings on examination of urine, without diagnosis'\n",
    "    elif 'R83.0' <= icd10_code <= 'R89.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R83-R89 Abnormal findings on examination of other body fluids, substances and tissues, without diagnosis'\n",
    "    elif 'R90.0' <= icd10_code <= 'R94.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R90-R94 Abnormal findings on diagnostic imaging and in function studies, without diagnosis'\n",
    "    elif 'R95.0' <= icd10_code <= 'R99.9':\n",
    "        return 'Chapter XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified', 'R95-R99 Ill-defined and unknown causes of mortality'\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'S00.0' <= icd10_code <= 'S09.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S00-S09 Injuries to the head'\n",
    "    elif 'S10.0' <= icd10_code <= 'S19.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S10-S19 Injuries to the neck'\n",
    "    elif 'S20.0' <= icd10_code <= 'S29.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S20-S29 Injuries to the thorax'\n",
    "    elif 'S30.0' <= icd10_code <= 'S39.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S30-S39 Injuries to the abdomen, lower back, lumbar spine and pelvis'\n",
    "    elif 'S40.0' <= icd10_code <= 'S49.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S40-S49 Injuries to the shoulder and upper arm'\n",
    "    elif 'S50.0' <= icd10_code <= 'S59.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S50-S59 Injuries to the elbow and forearm'\n",
    "    elif 'S60.0' <= icd10_code <= 'S69.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S60-S69 Injuries to the wrist and hand'\n",
    "    elif 'S70.0' <= icd10_code <= 'S79.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S70-S79 Injuries to the hip and thigh'\n",
    "    elif 'S80.0' <= icd10_code <= 'S89.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S80-S89 Injuries to the knee and lower leg'\n",
    "    elif 'S90.0' <= icd10_code <= 'S99.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'S90-S99 Injuries to the ankle and foot'\n",
    "    elif 'T00.0' <= icd10_code <= 'T07.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T00-T07 Injuries involving multiple body regions'\n",
    "    elif 'T08' <= icd10_code <= 'T14':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T08-T14 Injuries to unspecified part of trunk, limb or body region'\n",
    "    elif 'T08.0' <= icd10_code <= 'T14.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T08-T14 Injuries to unspecified part of trunk, limb or body region'\n",
    "    elif 'T15.0' <= icd10_code <= 'T19.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T15-T19 Effects of foreign body entering through natural orifice'\n",
    "    elif 'T20.0' <= icd10_code <= 'T25.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T20-T25 Burns and corrosions of external body surface, specified by site'\n",
    "    elif 'T26.0' <= icd10_code <= 'T28.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T26-T28 Burns and corrosions confined to eye and internal organs'\n",
    "    elif 'T29.0' <= icd10_code <= 'T32.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T29-T32 Burns and corrosions of multiple and unspecified body regions'\n",
    "    elif 'T33.0' <= icd10_code <= 'T35.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T33-T35 Frostbite'\n",
    "    elif 'T36.0' <= icd10_code <= 'T50.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T36-T50 Poisoning by drugs, medicaments and biological substances'\n",
    "    elif 'T51.0' <= icd10_code <= 'T65.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T51-T65 Toxic effects of substances chiefly nonmedicinal as to source'\n",
    "    elif 'T66.0' <= icd10_code <= 'T78.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T66-T78 Other and unspecified effects of external causes'\n",
    "    elif 'T66' <= icd10_code <= 'T66':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T66-T78 Other and unspecified effects of external causes'\n",
    "    elif 'T79.0' <= icd10_code <= 'T79.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T79-T79 Certain early complications of trauma'\n",
    "    elif 'T80.0' <= icd10_code <= 'T88.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T80-T88 Complications of surgical and medical care, not elsewhere classified'\n",
    "    elif 'T90.0' <= icd10_code <= 'T98.9':\n",
    "        return 'Chapter XIX Injury, poisoning and certain other consequences of external causes', 'T90-T98 Sequelae of injuries, of poisoning and of other consequences of external causes'    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    elif 'V01.0' <= icd10_code <= 'V09.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V01-V09 Pedestrian injured in transport accident'\n",
    "    elif 'V10.0' <= icd10_code <= 'V19.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V10-V19 Pedal cyclist injured in transport accident'\n",
    "    elif 'V20.0' <= icd10_code <= 'V29.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V20-V29 Motorcycle rider injured in transport accident'\n",
    "    elif 'V30.0' <= icd10_code <= 'V39.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V30-V39 Occupant of three-wheeled motor vehicle injured in transport accident'\n",
    "    elif 'V40.0' <= icd10_code <= 'V49.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V40-V49 Car occupant injured in transport accident'\n",
    "    elif 'V50.0' <= icd10_code <= 'V59.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V50-V59 Occupant of pick-up truck or van injured in transport accident'\n",
    "    elif 'V60.0' <= icd10_code <= 'V69.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V60-V69 Occupant of heavy transport vehicle injured in transport accident'\n",
    "    elif 'V70.0' <= icd10_code <= 'V79.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V70-V79 Bus occupant injured in transport accident'\n",
    "    elif 'V80.0' <= icd10_code <= 'V89.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V80-V89 Other land transport accidents'\n",
    "    elif 'V90.0' <= icd10_code <= 'V94.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V90-V94 Water transport accidents'\n",
    "    elif 'V95.0' <= icd10_code <= 'V97.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V95-V97 Air and space transport accidents'\n",
    "    elif 'V98.0' <= icd10_code <= 'V99.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'V98-V99 Other and unspecified transport accidents'\n",
    "    elif 'W00.0' <= icd10_code <= 'W19.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W00-W19 Falls'\n",
    "    elif 'W20.0' <= icd10_code <= 'W49.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W20-W49 Exposure to inanimate mechanical forces'\n",
    "    elif 'W50.0' <= icd10_code <= 'W64.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W50-W64 Exposure to animate mechanical forces'\n",
    "    elif 'W65.0' <= icd10_code <= 'W74.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W65-W74 Accidental drowning and submersion'\n",
    "    elif 'W75.0' <= icd10_code <= 'W84.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W75-W84 Other accidental threats to breathing'\n",
    "    elif 'W85.0' <= icd10_code <= 'W99.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'W85-W99 Exposure to electric current, radiation and extreme ambient air temperature and pressure'\n",
    "    elif 'X00.0' <= icd10_code <= 'X09.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X00-X09 Exposure to smoke, fire and flames'\n",
    "    elif 'X10.0' <= icd10_code <= 'X19.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X10-X19 Contact with heat and hot substances'\n",
    "    elif 'X20.0' <= icd10_code <= 'X29.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X20-X29 Contact with venomous animals and plants'\n",
    "    elif 'X30.0' <= icd10_code <= 'X39.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X30-X39 Exposure to forces of nature'\n",
    "    elif 'X40.0' <= icd10_code <= 'X49.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X40-X49 Accidental poisoning by and exposure to noxious substances'\n",
    "    elif 'X50.0' <= icd10_code <= 'X57.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X50-X57 Overexertion, travel and privation'\n",
    "    elif 'X58.0' <= icd10_code <= 'X59.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X58-X59 Accidental exposure to other and unspecified factors'\n",
    "    elif 'X60.0' <= icd10_code <= 'X84.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X60-X84 Intentional self-harm'\n",
    "    elif 'X85.0' <= icd10_code <= 'X99.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'X85-X99 Assault'\n",
    "    elif 'Y00.0' <= icd10_code <= 'Y09.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y00-Y09 Assault'\n",
    "    elif 'Y10.0' <= icd10_code <= 'Y34.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y10-Y34 Event of undetermined intent'\n",
    "    elif 'Y35.0' <= icd10_code <= 'Y36.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y35-Y36 Legal intervention and operations of war'\n",
    "    elif 'Y40.0' <= icd10_code <= 'Y59.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y40-Y59 Drugs, medicaments and biological substances causing adverse effects in therapeutic use'\n",
    "    elif 'Y60.0' <= icd10_code <= 'Y69.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y60-Y69 Misadventures to patients during surgical and medical care'\n",
    "    elif 'Y70.0' <= icd10_code <= 'Y82.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y70-Y82 Medical devices associated with adverse incidents in diagnostic and therapeutic use'\n",
    "    elif 'Y83.0' <= icd10_code <= 'Y84.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y83-Y84 Surgical and other medical procedures as the cause of abnormal reaction of the patient, or of later complication, without mention of misadventure at the time of the procedure'\n",
    "    elif 'Y85.0' <= icd10_code <= 'Y89.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y85-Y89 Sequelae of external causes of morbidity and mortality'\n",
    "    elif 'Y90.0' <= icd10_code <= 'Y98.9':\n",
    "        return 'Chapter XX External causes of morbidity and mortality', 'Y90-Y98 Supplementary factors related to causes of morbidity and mortality classified elsewhere'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'Z00.0' <= icd10_code <= 'Z13.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z00-Z13 Persons encountering health services for examination and investigation'\n",
    "    elif 'Z20.0' <= icd10_code <= 'Z29.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z20-Z29 Persons with potential health hazards related to communicable diseases'\n",
    "    elif 'Z30.0' <= icd10_code <= 'Z39.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z30-Z39 Persons encountering health services in circumstances related to reproduction'\n",
    "    elif 'Z40.0' <= icd10_code <= 'Z54.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z40-Z54 Persons encountering health services for specific procedures and health care'\n",
    "    elif 'Z55.0' <= icd10_code <= 'Z65.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z55-Z65 Persons with potential health hazards related to socioeconomic and psychosocial circumstances'\n",
    "    elif 'Z70.0' <= icd10_code <= 'Z76.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z70-Z76 Persons encountering health services in other circumstances'\n",
    "    elif 'Z80.0' <= icd10_code <= 'Z99.9':\n",
    "        return 'Chapter XXI Factors influencing health status and contact with health services', 'Z80-Z99 Persons with potential health hazards related to family and personal history and certain conditions influencing health status'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'U00.0' <= icd10_code <= 'U49.9':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U51' <= icd10_code <= 'U51':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U51.0' <= icd10_code <= 'U51.0':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U51.1' <= icd10_code <= 'U51.1':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U82.0' <= icd10_code <= 'U85.9':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U80.0' <= icd10_code <= 'U80.9':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U81.0' <= icd10_code <= 'U81.9':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U00-U49 Provisional assignment of new diseases of uncertain etiology or emergency use'\n",
    "    elif 'U88' <= icd10_code <= 'U89':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U82-U85 Resistance to antimicrobial and antineoplastic drugs'\n",
    "    elif 'U89.0' <= icd10_code <= 'U89.9':\n",
    "        return 'Chapter XXII Codes for special purposes', 'U82-U85 Resistance to antimicrobial and antineoplastic drugs'\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply the categorization function to create new columns\n",
    "heart_failure_Matched_cohort_with_Comorbidities[['Diseases Chapter', 'Diseases Sub-Chapter']] = heart_failure_Matched_cohort_with_Comorbidities['Combined ICD10 Codes'].apply(lambda x: categorize_icd10(x)).apply(pd.Series)\n",
    "\n",
    "# Define the column order\n",
    "#column_order = ['Participant ID', 'Year of Birth', 'Month of Birth', 'Sex', 'Ethnicity', 'Age', 'Age Group',\n",
    "#                 'Diagnosis Date', 'Diseases', 'ICD10 Codes', 'Diseases Sub-Chapter', 'Diseases Chapter',\n",
    "#                 'PH Types', 'Date of Death','Alive / Dead']\n",
    "\n",
    "# Rearrange columns\n",
    "#heart_failure_Matched_cohort_with_Comorbidities = PH_with_comorbidities_model[column_order]\n",
    "\n",
    "\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Check \"None\" or \"NaN\" values in either \"Diseases Chapter\" or \"Diseases Sub-Chapter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with \"None\" or \"NaN\" values in either \"Diseases Chapter\" or \"Diseases Sub-Chapter\"\n",
    "filtered_df = []\n",
    "filtered_df = heart_failure_Matched_cohort_with_Comorbidities[(heart_failure_Matched_cohort_with_Comorbidities['Diseases Chapter'].isna()) | (heart_failure_Matched_cohort_with_Comorbidities['Diseases Chapter'] == 'None') |\n",
    "                 (heart_failure_Matched_cohort_with_Comorbidities['Diseases Sub-Chapter'].isna()) | (heart_failure_Matched_cohort_with_Comorbidities['Diseases Sub-Chapter'] == 'None')]\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Drop duplicates based on \"Participant ID\" and \"ICD10 Codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on \"Participant ID\" and \"Diagnosis Date\"\n",
    "heart_failure_Matched_cohort_with_Comorbidities.drop_duplicates(subset=['Participant ID', 'Combined ICD10 Codes'], inplace=True)\n",
    "\n",
    "\n",
    "# Create dictionaries to store unique counts, row counts, NaN counts, and empty counts\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities = {}\n",
    "\n",
    "# Loop through columns and count unique items, row counts, NaN counts, and empty counts\n",
    "for column_heart_failure_Matched_cohort_with_Comorbidities in heart_failure_Matched_cohort_with_Comorbidities.columns:\n",
    "    unique_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].nunique()\n",
    "    row_count_heart_failure_Matched_cohort_with_Comorbidities = len(heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities])\n",
    "    nan_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].isna().sum()  # Count NaN values\n",
    "    empty_count_heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities].eq('').sum()  # Count empty string values\n",
    "\n",
    "    unique_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [unique_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    row_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [row_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    nan_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [nan_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "    empty_counts_heart_failure_Matched_cohort_with_Comorbidities[column_heart_failure_Matched_cohort_with_Comorbidities] = [empty_count_heart_failure_Matched_cohort_with_Comorbidities]\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = []\n",
    "\n",
    "unique_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(unique_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Unique Count'])\n",
    "row_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(row_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Row Count'])\n",
    "nan_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(nan_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['NaN Count'])\n",
    "empty_counts_heart_failure_Matched_cohort_with_Comorbidities2 = pd.DataFrame(empty_counts_heart_failure_Matched_cohort_with_Comorbidities, index=['Empty Count'])\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "result_heart_failure_Matched_cohort_with_Comorbidities = pd.concat([unique_counts_heart_failure_Matched_cohort_with_Comorbidities2, row_counts_heart_failure_Matched_cohort_with_Comorbidities2, nan_counts_heart_failure_Matched_cohort_with_Comorbidities2, empty_counts_heart_failure_Matched_cohort_with_Comorbidities2])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "\n",
    "display(result_heart_failure_Matched_cohort_with_Comorbidities)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', None)  # Adjust as needed to see all rows if it's a large output\n",
    "display(heart_failure_Matched_cohort_with_Comorbidities.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Create \"ICD10 Codes Range\" Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first portion of the \"Diseases Sub-Chapter\" values\n",
    "heart_failure_Matched_cohort_with_Comorbidities['ICD10 Codes Range'] = heart_failure_Matched_cohort_with_Comorbidities['Diseases Sub-Chapter'].str.extract(r'([A-Z]\\d+-[A-Z]\\d+)')\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with NaN values\n",
    "nan_rows = []\n",
    "nan_rows = heart_failure_Matched_cohort_with_Comorbidities[heart_failure_Matched_cohort_with_Comorbidities[['Combined ICD10 Diseases', 'Combined ICD10 Codes', 'Diseases Sub-Chapter', 'Diseases Chapter']].isnull().any(axis=1)]\n",
    "nan_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Combine \"Combined ICD10 Codes\" and \"Combined ICD10 Diseases\" into a new column named \"ICD10 Codes Diseases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_Matched_cohort_with_Comorbidities['ICD10 Codes Diseases'] = heart_failure_Matched_cohort_with_Comorbidities['Combined ICD10 Codes'] + ' - ' + heart_failure_Matched_cohort_with_Comorbidities['Combined ICD10 Diseases']\n",
    "\n",
    "# Rearrange columns\n",
    "#heart_failure_Matched_cohort_with_Comorbidities = heart_failure_Matched_cohort_with_Comorbidities[['Participant ID','Year of Birth', 'Month of Birth','Sex','Ethnicity','Age','Age Group','Diagnosis Date','ICD10 Codes Diseases','Diseases Sub-Chapter','Diseases Chapter','PH Types','Diseases','ICD10 Codes','ICD10 Codes Range','Alive / Dead','Date of Death']]\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Save the Data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Heart Failure Matched cohort with Comorbidities.csv'\n",
    "\n",
    "#### Use the to_csv method to save the DataFrame as a CSV file\n",
    "#heart_failure_Matched_cohort_with_Comorbidities.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "#heart_failure_Matched_cohort_with_Comorbidities = pd.read_csv('Heart Failure Matched cohort with Comorbidities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Heart Failure Sunburst Plots </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_Control_with_comorbidities_model_plotting = []\n",
    "heart_failure_Control_with_comorbidities_model_plotting = pd.read_csv('Heart Failure Control Cohort with Comorbidities Model (for Sunburst Plot).csv')\n",
    "\n",
    "# Calculate the sum of the 'Record Count' column\n",
    "total_count = []\n",
    "total_count = heart_failure_Control_with_comorbidities_model_plotting['Record Count'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Total Record Count:\", total_count)\n",
    "\n",
    "heart_failure_Control_with_comorbidities_model_plotting.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_length = []\n",
    "row_length = len(heart_failure_Control_with_comorbidities_model_plotting)\n",
    "print(row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Remove Heart Failure ICD10 Codes from Sunburst Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I50.0**, **I50.1** aand all ICD10 codes except selected Comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of ICD10 codes to keep\n",
    "codes_to_keep = []\n",
    "codes_to_keep = [\"E78.0\", \"I25.8\", \"J45.9\", \"I48\", \"I34.0\", \"I25.1\", \"I10\", \"E11.9\"]\n",
    "\n",
    "# Filter rows where the 'ICD10 Codes Diseases' column starts with any of the codes in the list\n",
    "heart_failure_Control_with_comorbidities_model_plotting = heart_failure_Control_with_comorbidities_model_plotting[\n",
    "    heart_failure_Control_with_comorbidities_model_plotting['ICD10 Codes Diseases'].str.split(' ').str[0].isin(codes_to_keep)\n",
    "]\n",
    "\n",
    "# Calculate the sum of the 'Record Count' column\n",
    "total_count = heart_failure_Control_with_comorbidities_model_plotting['Record Count'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Total Record Count:\", total_count)\n",
    "\n",
    "# Sort the DataFrame by 'Record Count' in descending order\n",
    "heart_failure_Control_with_comorbidities_model_plotting = heart_failure_Control_with_comorbidities_model_plotting.sort_values(\n",
    "    by='Record Count', ascending=False\n",
    ")\n",
    "\n",
    "# Display the top 5 rows\n",
    "heart_failure_Control_with_comorbidities_model_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_length = []\n",
    "row_length = len(heart_failure_Control_with_comorbidities_model_plotting)\n",
    "print(row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Display Sunburst plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.sunburst(heart_failure_Control_with_comorbidities_model_plotting, path=['Diseases Chapter', 'Diseases Sub-Chapter', 'ICD10 Codes Diseases'], values='Record Count')\n",
    "fig.update_layout(\n",
    "    width=1600,  # Set your desired width\n",
    "    height=1200  # Set your desired height\n",
    ")\n",
    "\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html('heart_failure_Control_with_comorbidities_sunburst_chart.html')\n",
    "\n",
    "# Open the HTML file in a new tab in your default web browser\n",
    "import webbrowser\n",
    "webbrowser.open('heart_failure_Control_with_comorbidities_sunburst_chart.html', new=2)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Create the \"post_heart_failure_matched_control_comorbidities_rows\" datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "heart_failure_Matched_cohort_with_Comorbidities = pd.read_csv('Heart Failure Matched cohort with Comorbidities.csv')\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df is your DataFrame\n",
    "result_df = []\n",
    "result_df = heart_failure_Matched_cohort_with_Comorbidities.copy()\n",
    "\n",
    "# Convert \"Combined ICD10 Diagnosis Date\" to datetime\n",
    "result_df[\"Combined ICD10 Diagnosis Date\"] = pd.to_datetime(result_df[\"Combined ICD10 Diagnosis Date\"])\n",
    "\n",
    "# Initialize an empty DataFrame for post-COPD rows\n",
    "post_copd_rows = pd.DataFrame()\n",
    "\n",
    "# List of heart_failure ICD10 codes to identify heart_failure diagnoses\n",
    "heart_failure_icd10_codes = ['I50.0', 'I50.1']\n",
    "\n",
    "# Function to filter rows diagnosed after the first heart_failure diagnosis\n",
    "def filter_post_heart_failure_rows(group):\n",
    "    heart_failure_rows = group[group[\"Combined ICD10 Codes\"].isin(heart_failure_icd10_codes)]\n",
    "    if not heart_failure_rows.empty:\n",
    "        # Get the index of the first heart_failure diagnosis\n",
    "        heart_failure_index = heart_failure_rows.index[0]\n",
    "        # Filter rows diagnosed after the first heart_failure diagnosis\n",
    "        post_heart_failure_rows = group[group[\"Combined ICD10 Diagnosis Date\"] > group.loc[heart_failure_index, \"Combined ICD10 Diagnosis Date\"]]\n",
    "        return post_heart_failure_rows\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Apply the function to each group of \"Participant ID\"\n",
    "post_heart_failure_rows = result_df.groupby(\"Participant ID\").apply(filter_post_heart_failure_rows).reset_index(drop=True)\n",
    "\n",
    "# Sort the data by \"Participant ID\" and \"Combined ICD10 Diagnosis Date\"\n",
    "post_heart_failure_rows.sort_values(by=['Participant ID', 'Combined ICD10 Diagnosis Date'], inplace=True)\n",
    "\n",
    "# Create a new DataFrame for post-heart_failure with comorbidities\n",
    "Post_heart_failure_with_comorbidities = post_heart_failure_rows.copy()\n",
    "\n",
    "# Mask for identifying heart_failure diagnosis\n",
    "heart_failure_mask = Post_heart_failure_with_comorbidities['Combined ICD10 Codes'].isin(heart_failure_icd10_codes)\n",
    "\n",
    "# Create a new column 'heart_failure Diagnosis Date' and fill it with the corresponding dates for heart_failure diagnoses\n",
    "Post_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = None\n",
    "Post_heart_failure_with_comorbidities.loc[heart_failure_mask, 'heart_failure Diagnosis Date'] = Post_heart_failure_with_comorbidities.loc[heart_failure_mask, 'Combined ICD10 Diagnosis Date']\n",
    "\n",
    "# Group by 'Participant ID' and fill NaN values in 'heart_failure Diagnosis Date' with the first diagnosis date for heart_failure\n",
    "Post_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = Post_heart_failure_with_comorbidities.groupby('Participant ID')['heart_failure Diagnosis Date'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Calculate 'heart_failure Matched followup Time' as the time difference in years\n",
    "Post_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'] = pd.to_datetime(Post_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'])\n",
    "Post_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = pd.to_datetime(Post_heart_failure_with_comorbidities['heart_failure Diagnosis Date'])\n",
    "Post_heart_failure_with_comorbidities['heart_failure Matched followup Time'] = ((Post_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'] - Post_heart_failure_with_comorbidities['heart_failure Diagnosis Date']).dt.days / 365.25).round(1)\n",
    "\n",
    "# Filter out rows with 'heart_failure Matched followup Time' less than or equal to 0\n",
    "Post_heart_failure_with_comorbidities_forest_plotting = Post_heart_failure_with_comorbidities[Post_heart_failure_with_comorbidities['heart_failure Matched followup Time'] > 0]\n",
    "\n",
    "# Display unique values of \"heart_failure Matched followup Time\"\n",
    "heart_failure_followup_times = Post_heart_failure_with_comorbidities_forest_plotting[\"heart_failure Matched followup Time\"].unique()\n",
    "print(\"heart_failure Matched followup Time values:\")\n",
    "display(heart_failure_followup_times)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Display rows where \"heart_failure Matched followup Time\" is less than or equal to 0 (should be none)\n",
    "rows_with_non_positive_followup = Post_heart_failure_with_comorbidities_forest_plotting[Post_heart_failure_with_comorbidities_forest_plotting[\"heart_failure Matched followup Time\"] <= 0]\n",
    "print(\"\\nRows with heart_failure Matched followup Time less than or equal to 0:\")\n",
    "display(rows_with_non_positive_followup)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"\\nPost_heart_failure with comorbidities forest plotting DataFrame:\")\n",
    "Post_heart_failure_with_comorbidities_forest_plotting.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values under the \"ICD10 Codes\" column\n",
    "unique_icd10_codes_Post_heart_failure_with_comorbidities = []\n",
    "unique_icd10_codes_Post_heart_failure_with_comorbidities = Post_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "\n",
    "# Print the unique ICD10 codes\n",
    "print(\"Unique ICD10 codes in Post_heart_failure_with_comorbidities_forest_plotting:\")\n",
    "print(unique_icd10_codes_Post_heart_failure_with_comorbidities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participant_ids = []\n",
    "unique_participant_ids = Post_heart_failure_with_comorbidities_forest_plotting[\"Participant ID\"].nunique()\n",
    "display(\"Number of unique Participant IDs:\", unique_participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Post heart_failure COMMON with comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#Post_heart_failure_with_comorbidities_forest_plotting.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Create the \"pre_heart_failure_matched_control_comorbidities_rows\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "heart_failure_Matched_cohort_with_Comorbidities = []\n",
    "heart_failure_Matched_cohort_with_Comorbidities = pd.read_csv('Heart Failure Matched cohort with Comorbidities.csv')\n",
    "heart_failure_Matched_cohort_with_Comorbidities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df is your DataFrame\n",
    "result_df = []\n",
    "result_df = heart_failure_Matched_cohort_with_Comorbidities.copy()\n",
    "\n",
    "# Convert \"Combined ICD10 Diagnosis Date\" to datetime\n",
    "result_df[\"Combined ICD10 Diagnosis Date\"] = pd.to_datetime(result_df[\"Combined ICD10 Diagnosis Date\"])\n",
    "\n",
    "# Initialize an empty DataFrame for pre-heart_failure rows\n",
    "pre_heart_failure_rows = pd.DataFrame()\n",
    "\n",
    "# List of heart_failure ICD10 codes to identify COPD diagnoses\n",
    "heart_failure_icd10_codes = ['I50.0', 'I50.1']\n",
    "\n",
    "# Function to filter rows diagnosed before and on the same date as heart_failure\n",
    "def filter_pre_heart_failure_rows(group):\n",
    "    heart_failure_rows = group[group[\"Combined ICD10 Codes\"].isin(heart_failure_icd10_codes)]\n",
    "    if not heart_failure_rows.empty:\n",
    "        # Get the index of the first heart_failure diagnosis\n",
    "        heart_failure_index = heart_failure_rows.index[0]\n",
    "        # Filter rows diagnosed before or on the same date as the first heart_failure diagnosis\n",
    "        pre_heart_failure_rows = group[group[\"Combined ICD10 Diagnosis Date\"] <= group.loc[heart_failure_index, \"Combined ICD10 Diagnosis Date\"]]\n",
    "        return pre_heart_failure_rows\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Apply the function to each group of \"Participant ID\"\n",
    "pre_heart_failure_rows = result_df.groupby(\"Participant ID\").apply(filter_pre_heart_failure_rows).reset_index(drop=True)\n",
    "\n",
    "# Sort the data by \"Participant ID\" and \"Combined ICD10 Diagnosis Date\"\n",
    "pre_heart_failure_rows.sort_values(by=['Participant ID', 'Combined ICD10 Diagnosis Date'], inplace=True)\n",
    "\n",
    "# Create a new DataFrame for pre-heart_failure with comorbidities\n",
    "Pre_heart_failure_with_comorbidities = pre_heart_failure_rows.copy()\n",
    "\n",
    "# Mask for identifying heart_failure diagnosis\n",
    "heart_failure_mask = Pre_heart_failure_with_comorbidities['Combined ICD10 Codes'].isin(heart_failure_icd10_codes)\n",
    "\n",
    "# Create a new column 'heart_failure Diagnosis Date' and fill it with the corresponding dates for heart_failure diagnoses\n",
    "Pre_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = None\n",
    "Pre_heart_failure_with_comorbidities.loc[heart_failure_mask, 'heart_failure Diagnosis Date'] = Pre_heart_failure_with_comorbidities.loc[heart_failure_mask, 'Combined ICD10 Diagnosis Date']\n",
    "\n",
    "# Group by 'Participant ID' and fill NaN values in 'heart_failure Diagnosis Date' with the first diagnosis date for heart_failure\n",
    "Pre_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = Pre_heart_failure_with_comorbidities.groupby('Participant ID')['heart_failure Diagnosis Date'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Calculate 'heart_failure Matched followup Time' as the time difference in years\n",
    "Pre_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'] = pd.to_datetime(Pre_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'])\n",
    "Pre_heart_failure_with_comorbidities['heart_failure Diagnosis Date'] = pd.to_datetime(Pre_heart_failure_with_comorbidities['heart_failure Diagnosis Date'])\n",
    "Pre_heart_failure_with_comorbidities['heart_failure Matched followup Time'] = ((Pre_heart_failure_with_comorbidities['Combined ICD10 Diagnosis Date'] - Pre_heart_failure_with_comorbidities['heart_failure Diagnosis Date']).dt.days / 365.25).round(1)\n",
    "\n",
    "# Filter out rows with 'heart_failure Matched followup Time' greater than 0\n",
    "Pre_heart_failure_with_comorbidities_forest_plotting = Pre_heart_failure_with_comorbidities[Pre_heart_failure_with_comorbidities['heart_failure Matched followup Time'] <= 0]\n",
    "\n",
    "# Display unique values of \"heart_failure Matched followup Time\"\n",
    "heart_failure_followup_times = Pre_heart_failure_with_comorbidities_forest_plotting[\"heart_failure Matched followup Time\"].unique()\n",
    "print(\"heart_failure Matched followup Time values:\")\n",
    "print(heart_failure_followup_times)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Display rows where \"heart_failure Matched followup Time\" is greater than 0 (should be none)\n",
    "rows_with_positive_followup = Pre_heart_failure_with_comorbidities_forest_plotting[Pre_heart_failure_with_comorbidities_forest_plotting[\"heart_failure Matched followup Time\"] > 0]\n",
    "print(\"\\nRows with heart_failure Matched followup Time greater than 0:\")\n",
    "display(rows_with_positive_followup)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"\\nPre_heart_failure with comorbidities forest plotting DataFrame:\")\n",
    "display(Pre_heart_failure_with_comorbidities_forest_plotting.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values under the \"ICD10 Codes\" column\n",
    "unique_icd10_codes_Pre_heart_failure_with_comorbidities = []\n",
    "unique_icd10_codes_Pre_heart_failure_with_comorbidities = Pre_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "\n",
    "# Print the unique ICD10 codes\n",
    "print(\"Unique ICD10 codes in Pre_heart_failure_with_comorbidities_forest_plotting:\")\n",
    "print(unique_icd10_codes_Pre_heart_failure_with_comorbidities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participant_ids = []\n",
    "unique_participant_ids = Pre_heart_failure_with_comorbidities_forest_plotting[\"Participant ID\"].nunique()\n",
    "display(\"Number of unique Participant IDs:\", unique_participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Pre heart_failure COMMON with comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#Pre_heart_failure_with_comorbidities_forest_plotting.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values under the \"ICD10 Codes\" column\n",
    "unique_icd10_codes_Pre_heart_failure = []\n",
    "unique_icd10_codes_Post_heart_failure = []\n",
    "\n",
    "unique_icd10_codes_Pre_heart_failure = Pre_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "unique_icd10_codes_Post_heart_failure = Post_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "\n",
    "# Convert the arrays to sets\n",
    "set_pre_heart_failure = set(unique_icd10_codes_Pre_heart_failure)\n",
    "set_post_heart_failure = set(unique_icd10_codes_Post_heart_failure)\n",
    "\n",
    "# Find the common ICD10 codes\n",
    "common_icd10_codes = set_pre_heart_failure.intersection(set_post_heart_failure)\n",
    "\n",
    "# Print the common ICD10 codes\n",
    "print(\"Common ICD10 codes in both Pre_heart_failure and Post_heart_failure datasets:\")\n",
    "print(common_icd10_codes)\n",
    "\n",
    "# Count the number of common codes\n",
    "count_common_icd10_codes = len(common_icd10_codes)\n",
    "print(\"Number of common ICD10 codes:\", count_common_icd10_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'common Pre-heart_failure and post-heart_failure icd10 codes.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#common_icd10_codes.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = []\n",
    "#common_icd10_codes_df = []\n",
    "# Assuming common_icd10_codes is a set\n",
    "#common_icd10_codes_df = pd.DataFrame(list(common_icd10_codes), columns=['ICD10 Codes'])\n",
    "\n",
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = 'common Pre-heart_failure and post-heart_failure icd10 codes.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "#common_icd10_codes_df.to_csv(file_path, index=False)\n",
    "\n",
    "#print(\"File saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Steps to find Pre_heart_failure and Post_heart_failure with Uncommon ICD10 Codes rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the common ICD10 codes from previous steps\n",
    "common_icd10_codes = set_pre_heart_failure.intersection(set_post_heart_failure)\n",
    "\n",
    "# Filter out rows with common ICD10 codes in Pre_heart_failure_with_comorbidities_forest_ploting\n",
    "filtered_Pre_heart_failure = []\n",
    "filtered_Pre_heart_failure = Pre_heart_failure_with_comorbidities_forest_plotting[~Pre_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].isin(common_icd10_codes)]\n",
    "\n",
    "# Filter out rows with common ICD10 codes in Post_heart_failure_with_comorbidities_forest_ploting\n",
    "filtered_Post_heart_failure  = []\n",
    "filtered_Post_heart_failure = Post_heart_failure_with_comorbidities_forest_plotting[~Post_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].isin(common_icd10_codes)]\n",
    "\n",
    "# Print the number of rows in the filtered dataframes to confirm the filtering\n",
    "print(\"Number of rows in filtered Pre_heart_failure_with_comorbidities_forest_ploting:\", filtered_Pre_heart_failure.shape[0])\n",
    "print(\"Number of rows in filtered Post_heart_failure_with_comorbidities_forest_ploting:\", filtered_Post_heart_failure.shape[0])\n",
    "print()\n",
    "\n",
    "# Display the first few rows of the filtered dataframes to verify the filtering\n",
    "print(\"Filtered Pre_heart_failure_with_comorbidities_forest_ploting:\")\n",
    "display(filtered_Pre_heart_failure.head(3))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Filtered Post_heart_failure_with_comorbidities_forest_ploting:\")\n",
    "display(filtered_Post_heart_failure.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of 'Combined ICD10 Codes' in each filtered dataset\n",
    "unique_pre_heart_failure_codes = []\n",
    "unique_post_heart_failure_codes = []\n",
    "unique_pre_heart_failure_codes = set(filtered_Pre_heart_failure['Combined ICD10 Codes'].unique())\n",
    "unique_post_heart_failure_codes = set(filtered_Post_heart_failure['Combined ICD10 Codes'].unique())\n",
    "\n",
    "# Find intersection between the two sets to check if there are any common codes\n",
    "common_codes = unique_pre_heart_failure_codes.intersection(unique_post_heart_failure_codes)\n",
    "\n",
    "# Print the result\n",
    "if len(common_codes) == 0:\n",
    "    print(\"No common 'Combined ICD10 Codes' found between filtered_Pre_heart_failure and filtered_Post_heart_failure.\")\n",
    "else:\n",
    "    print(\"Common 'Combined ICD10 Codes' found between filtered_Pre_heart_failure and filtered_Post_heart_failure:\")\n",
    "    print(common_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Pre heart_failure with comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#filtered_Pre_heart_failure.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Post heart_failure with comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#filtered_Post_heart_failure.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Common Pre_heart_failure and Post_heart_failure ICD10 codes Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values under the \"ICD10 Codes\" column\n",
    "unique_icd10_codes_Pre_heart_failure = []\n",
    "unique_icd10_codes_Post_heart_failure = []\n",
    "\n",
    "unique_icd10_codes_Pre_heart_failure = Pre_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "unique_icd10_codes_Post_heart_failure = Post_heart_failure_with_comorbidities_forest_plotting['Combined ICD10 Codes'].unique()\n",
    "\n",
    "# Convert the arrays to sets\n",
    "set_pre_heart_failure = set(unique_icd10_codes_Pre_heart_failure)\n",
    "set_post_heart_failure = set(unique_icd10_codes_Post_heart_failure)\n",
    "\n",
    "# Find the common ICD10 codes\n",
    "common_icd10_codes = set_pre_heart_failure.intersection(set_post_heart_failure)\n",
    "\n",
    "# Print the common ICD10 codes\n",
    "print(\"Common ICD10 codes in both Pre_heart_failure and Post_heart_failure datasets:\")\n",
    "#print(common_icd10_codes)\n",
    "# Create the DataFrame\n",
    "common_icd10_codes = pd.DataFrame(common_icd10_codes)\n",
    "common_icd10_codes.head(3)\n",
    "\n",
    "\n",
    "unique_participant_ids_count = []\n",
    "unique_participant_ids_count = common_icd10_codes.nunique()\n",
    "print(\"Number of unique Participant IDs:\", unique_participant_ids_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets = []\n",
    "Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets = pd.read_csv('common Pre-heart_failure and post-heart_failure icd10 codes.csv', header=None)\n",
    "Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets = Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets[0].tolist()\n",
    "\n",
    "\n",
    "#unique_participant_ids_count = []\n",
    "#unique_participant_ids_count = Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets.nunique()\n",
    "#print(\"Number of unique Participant IDs:\", unique_participant_ids_count)\n",
    "\n",
    "\n",
    "print(\"Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets:\")\n",
    "display(Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets[:5])  # Display the first 10 common ICD-10 codes\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Load your pre-heart_failure and post-heart_failure datasets\n",
    "Pre_heart_failure_Common_dataframe = []\n",
    "Post_heart_failure_Common_dataframe = []\n",
    "\n",
    "Pre_heart_failure_Common_dataframe = pd.read_csv('Pre heart_failure COMMON with comorbidities.csv')\n",
    "Post_heart_failure_Common_dataframe = pd.read_csv('Post heart_failure COMMON with comorbidities.csv')\n",
    "\n",
    "# Check the first few rows to ensure they are loaded correctly\n",
    "display(Pre_heart_failure_Common_dataframe.head(2))\n",
    "print()\n",
    "print()\n",
    "display(Post_heart_failure_Common_dataframe.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all common ICD-10 codes are present in the pre-heart_failure dataset\n",
    "pre_heart_failure_icd10_codes = Pre_heart_failure_Common_dataframe['Combined ICD10 Codes'].unique().tolist()\n",
    "missing_in_pre_heart_failure = [code for code in Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets if code not in pre_heart_failure_icd10_codes]\n",
    "\n",
    "# Check if all common ICD-10 codes are present in the post-heart_failure dataset\n",
    "post_heart_failure_icd10_codes = Post_heart_failure_Common_dataframe['Combined ICD10 Codes'].unique().tolist()\n",
    "missing_in_post_heart_failure = [code for code in Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets if code not in post_heart_failure_icd10_codes]\n",
    "\n",
    "# Print results\n",
    "#print(\"ICD-10 codes missing in Pre-heart_failure Common dataset:\")\n",
    "#print(missing_in_pre_heart_failure)\n",
    "#print()\n",
    "#print()\n",
    "\n",
    "#print(\"ICD-10 codes missing in Post-heart_failure Common dataset:\")\n",
    "#print(missing_in_post_heart_failure)\n",
    "\n",
    "# Filter pre-heart_failure and post-heart_failure DataFrames for common ICD-10 codes\n",
    "Pre_heart_failure_common = []\n",
    "Post_heart_failure_common = []\n",
    "\n",
    "Pre_heart_failure_common = Pre_heart_failure_Common_dataframe[Pre_heart_failure_Common_dataframe['Combined ICD10 Codes'].isin(Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets)]\n",
    "Post_heart_failure_common = Post_heart_failure_Common_dataframe[Post_heart_failure_Common_dataframe['Combined ICD10 Codes'].isin(Common_ICD10_codes_in_both_Pre_heart_failure_and_Post_heart_failure_datasets)]\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "#display(Pre_heart_failure_common.head(2))\n",
    "#display(Post_heart_failure_common.head(2))\n",
    "\n",
    "# Combine the filtered pre-heart_failure and post-heart_failure DataFrames\n",
    "Combined_heart_failure_common = []\n",
    "Combined_heart_failure_common = pd.concat([Pre_heart_failure_common, Post_heart_failure_common], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "display(Combined_heart_failure_common.head(3))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participant_ids_count = []\n",
    "unique_participant_ids_count = Combined_heart_failure_common['Participant ID'].nunique()\n",
    "print(\"Number of unique Participant IDs:\", unique_participant_ids_count)\n",
    "\n",
    "unique_Combined_ICD10_Diseases_count = []\n",
    "unique_Combined_ICD10_Diseases_count = Combined_heart_failure_common['Combined ICD10 Diseases'].nunique()\n",
    "print(\"Number of unique ICD10 Codes:\", unique_Combined_ICD10_Diseases_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#file_path = []\n",
    "#file_path = 'Combined heart_failure Common with comorbidities.csv'\n",
    "\n",
    "# Use the to_csv method to save the DataFrame as a CSV file\n",
    "#Combined_heart_failure_common.to_csv(file_path, index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Heart Failure Matched Control Forest Plots </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Pre_PH_dataframe = []\n",
    "Post_PH_dataframe = []\n",
    "Common_PH_dataframe = []\n",
    "categorized_conditions = []\n",
    "\n",
    "# Load the datasets\n",
    "Pre_PH_dataframe = pd.read_csv('Pre-PH Common PH Icd10 Codes.csv')\n",
    "Post_PH_dataframe = pd.read_csv('Post-PH Common PH Icd10 Codes.csv')\n",
    "Common_PH_dataframe = pd.read_csv('Common-PH Common PH Icd10 Codes.csv')\n",
    "\n",
    "# Define the conditions based on the final list\n",
    "conditions = {\n",
    "    \"Essential hypertension(1611)\": \"I10\",\n",
    "    \"Atrial fibrillation & flutter(868)\": \"I48\",\n",
    "    \"Pure hypercholesterolemia(830)\": \"E78.0\",\n",
    "    \"Atherosclerotic heart disease(682)\": \"I25.1\",\n",
    "    \"Type 2 diabetes mellitus(579)\": \"E11.9\",\n",
    "    \"Mitral (valve) insufficiency(438)\": \"I34.0\",\n",
    "    \"Asthma(410)\": \"J45.9\",\n",
    "    \"Chronic ischemic heart disease(229)\": \"I25.8\",\n",
    "}\n",
    "\n",
    "# Create a list to store the categorized data\n",
    "categorized_conditions_list = []\n",
    "\n",
    "# Helper function to count the occurrences of a condition in a dataframe\n",
    "def count_condition_in_df(df, icd_codes):\n",
    "    if isinstance(icd_codes, list):\n",
    "        return sum(df['ICD10 Codes'].isin(icd_codes))\n",
    "    else:\n",
    "        return sum(df['ICD10 Codes'] == icd_codes)\n",
    "\n",
    "# Populate the list\n",
    "for condition, icd_codes in conditions.items():\n",
    "    pre_ph_count = count_condition_in_df(Pre_PH_dataframe, icd_codes)\n",
    "    post_ph_count = count_condition_in_df(Post_PH_dataframe, icd_codes)\n",
    "    common_ph_count = count_condition_in_df(Common_PH_dataframe, icd_codes)\n",
    "    categorized_conditions_list.append({\n",
    "        'Condition': condition,\n",
    "        'ICD-10 Codes': icd_codes,\n",
    "        'Pre PH': pre_ph_count,\n",
    "        'Post PH': post_ph_count,\n",
    "        'Common PH': common_ph_count\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "categorized_conditions = pd.DataFrame(categorized_conditions_list)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(\"Categorized Conditions DataFrame:\")\n",
    "display(categorized_conditions)\n",
    "\n",
    "\n",
    "# Normalize the counts to get the frequencies\n",
    "total_ph_patients = 2727  # Total number of PH patients\n",
    "\n",
    "categorized_conditions['Pre PH Frequency'] = categorized_conditions['Pre PH'] / total_ph_patients\n",
    "categorized_conditions['Post PH Frequency'] = categorized_conditions['Post PH'] / total_ph_patients\n",
    "categorized_conditions['Common PH Frequency'] = categorized_conditions['Common PH'] / total_ph_patients\n",
    "\n",
    "# Prepare data for the forest plot\n",
    "conditions = categorized_conditions['Condition']\n",
    "pre_ph_freq = categorized_conditions['Pre PH Frequency']\n",
    "post_ph_freq = categorized_conditions['Post PH Frequency']\n",
    "common_ph_freq = categorized_conditions['Common PH Frequency']\n",
    "\n",
    "\n",
    "# Plotting function for the forest plot with a central line for PH diagnosis\n",
    "def plot_forest_with_central_line(conditions, pre_ph_freq, post_ph_freq, common_ph_freq):\n",
    "    fig, ax = plt.subplots(figsize=(22, 12))\n",
    "\n",
    "    y_pos = np.arange(len(conditions))\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "        before_freq = pre_ph_freq[i]\n",
    "        after_freq = post_ph_freq[i]\n",
    "        common_freq = common_ph_freq[i]\n",
    "\n",
    "        # Prioritize the color assignment: blue (common), green (pre), red (post)\n",
    "        if common_freq > 0:\n",
    "            color = 'blue'   # Common PH Frequency\n",
    "        elif before_freq > 0:\n",
    "            color = 'green'  # Pre PH Frequency\n",
    "        elif after_freq > 0:\n",
    "            color = 'red'    # Post PH Frequency\n",
    "        else:\n",
    "            color = 'gray'   # Default color for zero frequencies\n",
    "\n",
    "        # Plot the lines\n",
    "        ax.plot([0.5 - before_freq, 0.5 + after_freq], [y_pos[i], y_pos[i]], '-', color=color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i], 'o', color=color)\n",
    "\n",
    "        # Add percentage text next to the ends of the lines\n",
    "        before_percentage = before_freq * 100\n",
    "        after_percentage = after_freq * 100\n",
    "        ax.text(0.50 - before_freq - 0.05, y_pos[i], f'{before_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + after_freq + 0.05, y_pos[i], f'{after_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "\n",
    "        # Add thin horizontal lines extending from the bars to the ytick labels\n",
    "        ax.hlines(y=y_pos[i], xmin=0, xmax=0.5 - before_freq, colors='gray', linestyles='dotted', lw=0)\n",
    "        ax.hlines(y=y_pos[i], xmin=0.5 + after_freq, xmax=1, colors='gray', linestyles='dotted', lw=0)\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(conditions)\n",
    "    ax.set_xticks([0, 0.5, 0.91])\n",
    "    ax.set_xticklabels(['Comorbidities diagnosed before PH', 'Average PH Diagnosis\\n Time for all Patients', 'Comorbidities diagnosed after PH'])\n",
    "    ax.set_xlabel('Frequency', fontsize=16)  # Set font size of the x-axis label\n",
    "    ax.set_title('Forest Plot of Comorbidities Relative to PH Diagnosis', fontsize=18)  # Set font size of title\n",
    "\n",
    "    # Adjust the font size of xticks and yticks\n",
    "    ax.tick_params(axis='x', labelsize=14)  # Set font size of x-axis ticks\n",
    "    ax.tick_params(axis='y', labelsize=12)  # Set font size of y-axis ticks\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.axvline(0.5, color='black', linestyle='--', lw=6)\n",
    "\n",
    "    # Create custom legend with adjusted font size and position\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='green', lw=18),\n",
    "        plt.Line2D([0], [0], color='red', lw=18),\n",
    "        plt.Line2D([0], [0], color='blue', lw=18)\n",
    "    ]\n",
    "    \n",
    "    # Adjust legend position, fontsize, and size\n",
    "    ax.legend(custom_lines, ['Pre-PH Comorbidities', 'Post-PH Comorbidities', 'Common Comorbidities'], loc='upper right', fontsize=14, \n",
    "              bbox_to_anchor=(0.99, 0.99), borderaxespad=0., markerscale=1.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the forest plot\n",
    "plot_forest_with_central_line(conditions, pre_ph_freq, post_ph_freq, common_ph_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Pre_COPD_dataframe =[]\n",
    "Post_COPD_dataframe = []\n",
    "Common_COPD_dataframe = []\n",
    "\n",
    "# Assume these dataframes are defined elsewhere in your code\n",
    "Pre_COPD_dataframe = pd.read_csv('Pre COPD COMMON with comorbidities.csv')\n",
    "Post_COPD_dataframe = pd.read_csv('Post COPD COMMON with comorbidities.csv')\n",
    "Common_COPD_dataframe = pd.read_csv('Combined COPD Common with comorbidities.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Define the conditions based on the final list\n",
    "copd_conditions = {\n",
    "    \"Essential hypertension(1138)\": \"I10\",\n",
    "    \"Atrial fibrillation & flutter(231)\": \"I48\",\n",
    "    \"Pure hypercholesterolemia(543)\": \"E78.0\",\n",
    "    \"Atherosclerotic heart disease(297)\": \"I25.1\",\n",
    "    \"Type 2 diabetes mellitus(417)\": \"E11.9\",\n",
    "    \"Mitral (valve) insufficiency(62)\": \"I34.0\",\n",
    "    \"Asthma(1377)\": \"J45.9\",\n",
    "    \"Chronic ischemic heart disease(140)\": \"I25.8\",\n",
    "\n",
    "}\n",
    "\n",
    "# Create a list to store the categorized data\n",
    "categorized_copd_conditions_list = []\n",
    "\n",
    "# Helper function to count the occurrences of a condition in a dataframe\n",
    "def count_copd_condition_in_df(df, icd_codes):\n",
    "    if isinstance(icd_codes, list):\n",
    "        return sum(df['Combined ICD10 Codes'].isin(icd_codes))\n",
    "    else:\n",
    "        return sum(df['Combined ICD10 Codes'] == icd_codes)\n",
    "\n",
    "# Populate the list for COPD conditions\n",
    "for condition, icd_codes in copd_conditions.items():\n",
    "    pre_copd_count = count_copd_condition_in_df(Pre_COPD_dataframe, icd_codes)\n",
    "    post_copd_count = count_copd_condition_in_df(Post_COPD_dataframe, icd_codes)\n",
    "    common_copd_count = count_copd_condition_in_df(Common_COPD_dataframe, icd_codes)\n",
    "    categorized_copd_conditions_list.append({\n",
    "        'Condition': condition,\n",
    "        'Combined ICD-10 Codes': icd_codes,\n",
    "        'Pre COPD': pre_copd_count,\n",
    "        'Common COPD': common_copd_count,\n",
    "        'Post COPD': post_copd_count\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "categorized_copd_conditions = pd.DataFrame(categorized_copd_conditions_list)\n",
    "\n",
    "# Reorder the columns as requested\n",
    "categorized_copd_conditions = categorized_copd_conditions[\n",
    "    [\"Condition\", \"Combined ICD-10 Codes\", \"Pre COPD\", \"Common COPD\", \"Post COPD\"]\n",
    "]\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(\"Categorized COPD Conditions DataFrame:\")\n",
    "display(categorized_copd_conditions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming categorized_copd_conditions DataFrame is already created\n",
    "total_copd_patients = 2441  # Total number of COPD patients\n",
    "\n",
    "# Normalize the counts to get the frequencies\n",
    "categorized_copd_conditions['Pre COPD Frequency'] = categorized_copd_conditions['Pre COPD'] / total_copd_patients\n",
    "categorized_copd_conditions['Post COPD Frequency'] = categorized_copd_conditions['Post COPD'] / total_copd_patients\n",
    "categorized_copd_conditions['Common COPD Frequency'] = categorized_copd_conditions['Common COPD'] / total_copd_patients\n",
    "\n",
    "# Prepare data for the forest plot\n",
    "conditions = categorized_copd_conditions['Condition']\n",
    "pre_copd_freq = categorized_copd_conditions['Pre COPD Frequency']\n",
    "post_copd_freq = categorized_copd_conditions['Post COPD Frequency']\n",
    "common_copd_freq = categorized_copd_conditions['Common COPD Frequency']\n",
    "\n",
    "# Plotting function for the forest plot with a central line for COPD diagnosis\n",
    "def plot_forest_with_central_line(conditions, pre_copd_freq, post_copd_freq, common_copd_freq):\n",
    "    fig, ax = plt.subplots(figsize=(22, 12))\n",
    "\n",
    "    y_pos = np.arange(len(conditions))\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "        before_freq = pre_copd_freq[i]\n",
    "        after_freq = post_copd_freq[i]\n",
    "        common_freq = common_copd_freq[i]\n",
    "\n",
    "        # Prioritize the color assignment: blue (common), green (pre), red (post)\n",
    "        if common_freq > 0:\n",
    "            color = 'blue'   # Common copd Frequency\n",
    "        elif before_freq > 0:\n",
    "            color = 'green'  # Pre copd Frequency\n",
    "        elif after_freq > 0:\n",
    "            color = 'red'    # Post copd Frequency\n",
    "        else:\n",
    "            color = 'gray'   # Default color for zero frequencies\n",
    "\n",
    "        # Plot the lines\n",
    "        ax.plot([0.5 - before_freq, 0.5 + after_freq], [y_pos[i], y_pos[i]], '-', color=color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i], 'o', color=color)\n",
    "\n",
    "        # Add percentage text next to the ends of the lines\n",
    "        before_percentage = before_freq * 100\n",
    "        after_percentage = after_freq * 100\n",
    "        ax.text(0.50 - before_freq - 0.05, y_pos[i], f'{before_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + after_freq + 0.05, y_pos[i], f'{after_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "\n",
    "        # Add thin horizontal lines extending from the bars to the ytick labels\n",
    "        ax.hlines(y=y_pos[i], xmin=0, xmax=0.5 - before_freq, colors='gray', linestyles='dotted', lw=0)\n",
    "        ax.hlines(y=y_pos[i], xmin=0.5 + after_freq, xmax=1, colors='gray', linestyles='dotted', lw=0)\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(conditions)\n",
    "    ax.set_xticks([0, 0.5, 0.91])\n",
    "    ax.set_xticklabels(['Comorbidities diagnosed before COPD', 'Average COPD Diagnosis\\n Time for all Patients', 'Comorbidities diagnosed after COPD'])\n",
    "    ax.set_xlabel('Frequency', fontsize=16)  # Set font size of the x-axis label\n",
    "    ax.set_title('Forest Plot of Comorbidities Relative to COPD Diagnosis', fontsize=18)  # Set font size of title\n",
    "\n",
    "    # Adjust the font size of xticks and yticks\n",
    "    ax.tick_params(axis='x', labelsize=14)  # Set font size of x-axis ticks\n",
    "    ax.tick_params(axis='y', labelsize=12)  # Set font size of y-axis ticks\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.axvline(0.5, color='black', linestyle='--', lw=6)\n",
    "\n",
    "    # Create custom legend with adjusted font size and position\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='green', lw=18),\n",
    "        plt.Line2D([0], [0], color='red', lw=18),\n",
    "        plt.Line2D([0], [0], color='blue', lw=18)\n",
    "    ]\n",
    "    \n",
    "    # Adjust legend position, fontsize, and size\n",
    "    ax.legend(custom_lines, ['Pre-COPD Comorbidities', 'Post-COPD Comorbidities', 'Common Comorbidities'], loc='upper right', fontsize=14, \n",
    "              bbox_to_anchor=(0.99, 0.99), borderaxespad=0., markerscale=1.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the forest plot\n",
    "plot_forest_with_central_line(conditions, pre_copd_freq, post_copd_freq, common_copd_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Pre_heart_failure_dataframe =[]\n",
    "Post_heart_failure_dataframe = []\n",
    "Common_heart_failure_dataframe = []\n",
    "\n",
    "# Assume these dataframes are defined elsewhere in your code\n",
    "Pre_heart_failure_dataframe = pd.read_csv('Pre heart_failure COMMON with comorbidities.csv')\n",
    "Post_heart_failure_dataframe = pd.read_csv('Post heart_failure COMMON with comorbidities.csv')\n",
    "Common_heart_failure_dataframe = pd.read_csv('Combined heart_failure Common with comorbidities.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Define the conditions based on the final list\n",
    "heart_failure_conditions = {\n",
    "    \"Essential hypertension(1138)\": \"I10\",\n",
    "    \"Atrial fibrillation & flutter(231)\": \"I48\",\n",
    "    \"Pure hypercholesterolemia(543)\": \"E78.0\",\n",
    "    \"Atherosclerotic heart disease(297)\": \"I25.1\",\n",
    "    \"Type 2 diabetes mellitus(417)\": \"E11.9\",\n",
    "    \"Mitral (valve) insufficiency(62)\": \"I34.0\",\n",
    "    \"Asthma(1377)\": \"J45.9\",\n",
    "    \"Chronic ischemic heart disease(140)\": \"I25.8\",\n",
    "\n",
    "}\n",
    "\n",
    "# Create a list to store the categorized data\n",
    "categorized_heart_failure_conditions_list = []\n",
    "\n",
    "# Helper function to count the occurrences of a condition in a dataframe\n",
    "def count_heart_failure_condition_in_df(df, icd_codes):\n",
    "    if isinstance(icd_codes, list):\n",
    "        return sum(df['Combined ICD10 Codes'].isin(icd_codes))\n",
    "    else:\n",
    "        return sum(df['Combined ICD10 Codes'] == icd_codes)\n",
    "\n",
    "# Populate the list for heart_failure conditions\n",
    "for condition, icd_codes in heart_failure_conditions.items():\n",
    "    pre_heart_failure_count = count_heart_failure_condition_in_df(Pre_heart_failure_dataframe, icd_codes)\n",
    "    post_heart_failure_count = count_heart_failure_condition_in_df(Post_heart_failure_dataframe, icd_codes)\n",
    "    common_heart_failure_count = count_heart_failure_condition_in_df(Common_heart_failure_dataframe, icd_codes)\n",
    "    categorized_heart_failure_conditions_list.append({\n",
    "        'Condition': condition,\n",
    "        'Combined ICD-10 Codes': icd_codes,\n",
    "        'Pre heart_failure': pre_heart_failure_count,\n",
    "        'Common heart_failure': common_heart_failure_count,\n",
    "        'Post heart_failure': post_heart_failure_count\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "categorized_heart_failure_conditions = pd.DataFrame(categorized_heart_failure_conditions_list)\n",
    "\n",
    "# Reorder the columns as requested\n",
    "categorized_heart_failure_conditions = categorized_heart_failure_conditions[\n",
    "    [\"Condition\", \"Combined ICD-10 Codes\", \"Pre heart_failure\", \"Common heart_failure\", \"Post heart_failure\"]\n",
    "]\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(\"Categorized heart_failure Conditions DataFrame:\")\n",
    "display(categorized_heart_failure_conditions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming categorized_copd_conditions DataFrame is already created\n",
    "total_heart_failure_patients = 2441  # Total number of heart_failure patients\n",
    "\n",
    "# Normalize the counts to get the frequencies\n",
    "categorized_heart_failure_conditions['Pre heart_failure Frequency'] = categorized_heart_failure_conditions['Pre heart_failure'] / total_heart_failure_patients\n",
    "categorized_heart_failure_conditions['Post heart_failure Frequency'] = categorized_heart_failure_conditions['Post heart_failure'] / total_heart_failure_patients\n",
    "categorized_heart_failure_conditions['Common heart_failure Frequency'] = categorized_heart_failure_conditions['Common heart_failure'] / total_heart_failure_patients\n",
    "\n",
    "# Prepare data for the forest plot\n",
    "conditions = categorized_heart_failure_conditions['Condition']\n",
    "pre_heart_failure_freq = categorized_heart_failure_conditions['Pre heart_failure Frequency']\n",
    "post_heart_failure_freq = categorized_heart_failure_conditions['Post heart_failure Frequency']\n",
    "common_heart_failure_freq = categorized_heart_failure_conditions['Common heart_failure Frequency']\n",
    "\n",
    "# Plotting function for the forest plot with a central line for heart_failure diagnosis\n",
    "def plot_forest_with_central_line(conditions, pre_heart_failure_freq, post_heart_failure_freq, common_heart_failure_freq):\n",
    "    fig, ax = plt.subplots(figsize=(22, 12))\n",
    "\n",
    "    y_pos = np.arange(len(conditions))\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "        before_freq = pre_heart_failure_freq[i]\n",
    "        after_freq = post_heart_failure_freq[i]\n",
    "        common_freq = common_heart_failure_freq[i]\n",
    "\n",
    "        # Prioritize the color assignment: blue (common), green (pre), red (post)\n",
    "        if common_freq > 0:\n",
    "            color = 'blue'   # Common copd Frequency\n",
    "        elif before_freq > 0:\n",
    "            color = 'green'  # Pre copd Frequency\n",
    "        elif after_freq > 0:\n",
    "            color = 'red'    # Post copd Frequency\n",
    "        else:\n",
    "            color = 'gray'   # Default color for zero frequencies\n",
    "\n",
    "        # Plot the lines\n",
    "        ax.plot([0.5 - before_freq, 0.5 + after_freq], [y_pos[i], y_pos[i]], '-', color=color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i], 'o', color=color)\n",
    "\n",
    "        # Add percentage text next to the ends of the lines\n",
    "        before_percentage = before_freq * 100\n",
    "        after_percentage = after_freq * 100\n",
    "        ax.text(0.50 - before_freq - 0.05, y_pos[i], f'{before_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + after_freq + 0.05, y_pos[i], f'{after_percentage:.1f}%', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "\n",
    "        # Add thin horizontal lines extending from the bars to the ytick labels\n",
    "        ax.hlines(y=y_pos[i], xmin=0, xmax=0.5 - before_freq, colors='gray', linestyles='dotted', lw=0)\n",
    "        ax.hlines(y=y_pos[i], xmin=0.5 + after_freq, xmax=1, colors='gray', linestyles='dotted', lw=0)\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(conditions)\n",
    "    ax.set_xticks([0, 0.5, 0.91])\n",
    "    ax.set_xticklabels(['Comorbidities diagnosed before heart_failure', 'heart_failure Diagnosis\\n Time for all Patients', 'Comorbidities diagnosed after heart_failure'])\n",
    "    ax.set_xlabel('Frequency', fontsize=16)  # Set font size of the x-axis label\n",
    "    ax.set_title('Forest Plot of Comorbidities Relative to heart_failure Diagnosis', fontsize=18)  # Set font size of title\n",
    "\n",
    "    # Adjust the font size of xticks and yticks\n",
    "    ax.tick_params(axis='x', labelsize=14)  # Set font size of x-axis ticks\n",
    "    ax.tick_params(axis='y', labelsize=12)  # Set font size of y-axis ticks\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.axvline(0.5, color='black', linestyle='--', lw=6)\n",
    "\n",
    "    # Create custom legend with adjusted font size and position\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='green', lw=18),\n",
    "        plt.Line2D([0], [0], color='red', lw=18),\n",
    "        plt.Line2D([0], [0], color='blue', lw=18)\n",
    "    ]\n",
    "    \n",
    "    # Adjust legend position, fontsize, and size\n",
    "    ax.legend(custom_lines, ['Pre-heart_failure Comorbidities', 'Post-heart_failure Comorbidities', 'Common heart_failure Comorbidities'], loc='upper right', fontsize=14, \n",
    "              bbox_to_anchor=(0.99, 0.99), borderaxespad=0., markerscale=1.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the forest plot\n",
    "plot_forest_with_central_line(conditions, pre_heart_failure_freq, post_heart_failure_freq, common_heart_failure_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Combine Forest Plot (Based on Number of Individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Pre_PH_dataframe = []\n",
    "Post_PH_dataframe = []\n",
    "Common_PH_dataframe = []\n",
    "Pre_COPD_dataframe = []\n",
    "Post_COPD_dataframe = []\n",
    "Common_COPD_dataframe = []\n",
    "Pre_heart_failure_dataframe = []\n",
    "Post_heart_failure_dataframe = []\n",
    "Common_heart_failure_dataframe = []\n",
    "\n",
    "# Load your data (adjust file paths as necessary)\n",
    "Pre_PH_dataframe = pd.read_csv('Pre-PH Common PH Icd10 Codes.csv')\n",
    "Post_PH_dataframe = pd.read_csv('Post-PH Common PH Icd10 Codes.csv')\n",
    "Common_PH_dataframe = pd.read_csv('Common-PH Common PH Icd10 Codes.csv')\n",
    "\n",
    "Pre_COPD_dataframe = pd.read_csv('Pre COPD COMMON with comorbidities.csv')\n",
    "Pre_COPD_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "Post_COPD_dataframe = pd.read_csv('Post COPD COMMON with comorbidities.csv')\n",
    "Post_COPD_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "Common_COPD_dataframe = pd.read_csv('Combined COPD Common with comorbidities.csv')\n",
    "Common_COPD_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "Pre_heart_failure_dataframe = pd.read_csv('Pre heart_failure COMMON with comorbidities.csv')\n",
    "Pre_heart_failure_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "Post_heart_failure_dataframe = pd.read_csv('Post heart_failure COMMON with comorbidities.csv')\n",
    "Post_heart_failure_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "Common_heart_failure_dataframe = pd.read_csv('Combined heart_failure Common with comorbidities.csv')\n",
    "Common_heart_failure_dataframe.rename(columns={'Combined ICD10 Codes': 'ICD10 Codes'}, inplace=True)\n",
    "\n",
    "# Define the conditions and corresponding ICD-10 codes (adjust as necessary)\n",
    "#onditions = {\n",
    "#   \"Essential\\n hypertension\": \"I10\",\n",
    "#   \"Atrial fibrillation\\n& flutter\": \"I48\",\n",
    "#   \"Pure\\n hypercholesterolemia\": \"E78.0\",\n",
    "#   \"Atherosclerotic\\neart disease\": \"I25.1\",\n",
    "#   \"Type 2 diabetes\\nellitus\": \"E11.9\",\n",
    "#   \"Mitral (valve) insufficiency\": \"I34.0\",\n",
    "#   \"Asthma\": \"J45.9\",\n",
    "#   \"Chronic ischemic heart disease\": \"I25.8\",\n",
    "#   \"Tobacco use\": \"Z72.0\",\n",
    "#   \"Obesity\": \"E66.8\"\n",
    "#}\n",
    "# Define the conditions and corresponding ICD-10 codes (adjust as necessary)\n",
    "conditions = {\n",
    "    \"Essential\\n hypertension\": \"I10\",\n",
    "    \"Atrial fibrillation\\n& flutter\": \"I48\",\n",
    "    \"Pure\\n hypercholesterolemia\": \"E78.0\",\n",
    "    \"Atherosclerotic\\n heart disease\": \"I25.1\",\n",
    "    \"Type 2 diabetes\\n Mellitus\": \"E11.9\",\n",
    "    \"Asthma\": \"J45.9\",\n",
    "    \"Chronic ischemic \\n heart disease\": \"I25.8\",\n",
    "    \"Mitral (valve)\\n insufficiency\": \"I34.0\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Plotting function for the combined forest plot\n",
    "def plot_combined_forest_with_central_line(conditions,pre_ph_freq, post_ph_freq, common_ph_freq, \n",
    "                                           pre_copd_freq, post_copd_freq, common_copd_freq,\n",
    "                                           pre_heart_failure_freq, post_heart_failure_freq, common_heart_failure_freq):\n",
    "    fig, ax = plt.subplots(figsize=(22, 15))\n",
    "    #y_pos = np.arange(len(conditions))\n",
    "    y_pos = [i * 1.5 for i in range(len(conditions))]\n",
    "\n",
    "\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "        ph_before_freq = pre_ph_freq[i]\n",
    "        ph_after_freq = post_ph_freq[i]\n",
    "        ph_common_freq = common_ph_freq[i]\n",
    "\n",
    "        copd_before_freq = pre_copd_freq[i]\n",
    "        copd_after_freq = post_copd_freq[i]\n",
    "        copd_common_freq = common_copd_freq[i]\n",
    "        \n",
    "        heart_failure_before_freq = pre_heart_failure_freq[i]\n",
    "        heart_failure_after_freq = post_heart_failure_freq[i]\n",
    "        heart_failure_common_freq = common_heart_failure_freq[i]\n",
    "\n",
    "        # PH color: gray for this combined plot\n",
    "        if ph_common_freq > 0:\n",
    "            ph_color = 'gray'\n",
    "        elif ph_before_freq > 0:\n",
    "            ph_color = 'gray'\n",
    "        elif ph_after_freq > 0:\n",
    "            ph_color = 'gray'\n",
    "        else:\n",
    "            ph_color = 'lightgray'\n",
    "\n",
    "        # COPD color: green\n",
    "        if copd_common_freq > 0:\n",
    "            copd_color = 'green'\n",
    "        elif copd_before_freq > 0:\n",
    "            copd_color = 'green'\n",
    "        elif copd_after_freq > 0:\n",
    "            copd_color = 'green'\n",
    "        else:\n",
    "            copd_color = 'green'\n",
    "            \n",
    "            \n",
    "        # heart_failure color: green\n",
    "        if heart_failure_common_freq > 0:\n",
    "            heart_failure_color = 'brown'\n",
    "        elif heart_failure_before_freq > 0:\n",
    "            heart_failure_color = 'brown'\n",
    "        elif heart_failure_after_freq > 0:\n",
    "            heart_failure_color = 'brown'\n",
    "        else:\n",
    "            heart_failure_color = 'brown'\n",
    "\n",
    "        # Plot PH bars\n",
    "        ax.plot([0.5 - ph_before_freq, 0.5 + ph_after_freq], [y_pos[i], y_pos[i]], '-', color=ph_color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i], 'o', color=ph_color)\n",
    "\n",
    "        # Plot COPD bars slightly offset for clarity\n",
    "        ax.plot([0.5 - copd_before_freq, 0.5 + copd_after_freq], [y_pos[i] - 0.3, y_pos[i] - 0.3], '-', color=copd_color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i] - 0.3, 'o', color=copd_color)\n",
    "        \n",
    "        \n",
    "        # Plot Heart Failure bars further offset for clarity\n",
    "        ax.plot([0.5 - heart_failure_before_freq, 0.5 + heart_failure_after_freq], [y_pos[i] - 0.6, y_pos[i] - 0.6], '-', color=heart_failure_color, lw=18)\n",
    "        ax.plot(0.5, y_pos[i] - 0.6, 'o', color=heart_failure_color)\n",
    "\n",
    "        \n",
    "        # Calculate percentage values for PH\n",
    "        ph_before_percentage = ph_before_freq * 100\n",
    "        ph_after_percentage = ph_after_freq * 100\n",
    "\n",
    "        # Add participant count and percentage text next to the ends of the lines for PH\n",
    "        ph_before_count = categorized_conditions['Pre PH'].iloc[i]\n",
    "        ph_after_count = categorized_conditions['Post PH'].iloc[i]\n",
    "        ax.text(0.46 - ph_before_freq - 0.05, y_pos[i], f'{ph_before_count} ({ph_before_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + ph_after_freq + 0.05, y_pos[i], f'{ph_after_count} ({ph_after_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        \n",
    "        # Calculate percentage values for COPD\n",
    "        copd_before_percentage = copd_before_freq * 100\n",
    "        copd_after_percentage = copd_after_freq * 100\n",
    "\n",
    "        # Add participant count and percentage text for COPD\n",
    "        copd_before_count = categorized_copd_conditions['Pre COPD'].iloc[i]\n",
    "        copd_after_count = categorized_copd_conditions['Post COPD'].iloc[i]\n",
    "        ax.text(0.46 - copd_before_freq - 0.05, y_pos[i] - 0.3, f'{copd_before_count} ({copd_before_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + copd_after_freq + 0.05, y_pos[i] - 0.3, f'{copd_after_count} ({copd_after_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate percentage values for heart_failure\n",
    "        heart_failure_before_percentage = heart_failure_before_freq * 100\n",
    "        heart_failure_after_percentage = heart_failure_after_freq * 100\n",
    "\n",
    "        # Add participant count and percentage text for Heart Failure\n",
    "        heart_failure_before_count = categorized_heart_failure_conditions['Pre heart_failure'].iloc[i]\n",
    "        heart_failure_after_count = categorized_heart_failure_conditions['Post heart_failure'].iloc[i]\n",
    "        \n",
    "        ax.text(0.46 - heart_failure_before_freq - 0.05, y_pos[i] - 0.6, f'{heart_failure_before_count} ({heart_failure_before_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        ax.text(0.47 + heart_failure_after_freq + 0.05, y_pos[i] - 0.6, f'{heart_failure_after_count} ({heart_failure_after_percentage:.1f}%)', \n",
    "                verticalalignment='center', fontsize=13, color='black')\n",
    "        \n",
    "        #ax.text(0.46 - heart_failure_before_freq - 0.05, y_pos[i] - 0.6, f'{heart_failure_before_freq * 100:.1f}%', \n",
    "        #        verticalalignment='center', fontsize=14, color='black')\n",
    "        #ax.text(0.47 + heart_failure_after_freq + 0.05, y_pos[i] - 0.6, f'{heart_failure_after_freq * 100:.1f}%', \n",
    "        #        verticalalignment='center', fontsize=14, color='black')\n",
    "\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(conditions)\n",
    "    ax.set_xticks([0, 0.5, 0.91])\n",
    "    ax.set_xticklabels(['Comorbidities diagnosed\\n before PH/COPD/HF', 'PH, COPD, HF\\n Diagnosis Date', 'Comorbidities diagnosed\\n after PH/COPD/HF'])\n",
    "    #ax.set_xlabel('Frequency', fontsize=20, fontweight='bold')  # Set font size of the x-axis label\n",
    "    ax.set_title('Timing and Frequency of Comorbidities in PH, COPD, and Heart Failure Populations', fontsize=16, fontweight='bold')  # Set font size of title\n",
    "\n",
    "    # Adjust the font size of xticks and yticks\n",
    "    ax.tick_params(axis='x', labelsize=15)  # Set font size of x-axis ticks\n",
    "    ax.tick_params(axis='y', labelsize=15)  # Set font size of y-axis ticks\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.axvline(0.5, color='black', linestyle='--', lw=6)\n",
    "\n",
    "    # Create custom legend\n",
    "    # Create custom legend\n",
    "    custom_lines = [\n",
    "        plt.Line2D([0], [0], color='gray', lw=18),\n",
    "        plt.Line2D([0], [0], color='green', lw=18),\n",
    "        plt.Line2D([0], [0], color='brown', lw=18)\n",
    "    ]\n",
    "    \n",
    "    # Adjust legend position, font size, and description\n",
    "    ax.legend(custom_lines, ['PH Comorbidities', 'COPD Comorbidities', 'Heart Failure Comorbidities'], loc='upper right', fontsize=14, \n",
    "              bbox_to_anchor=(0.99, 0.99), borderaxespad=0., markerscale=1.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to plot\n",
    "plot_combined_forest_with_central_line(conditions,pre_ph_freq, post_ph_freq, common_ph_freq, \n",
    "                                       pre_copd_freq, post_copd_freq, common_copd_freq,\n",
    "                                       pre_heart_failure_freq, post_heart_failure_freq, common_heart_failure_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D2B48C; padding: 10px;\">\n",
    "    <h2><center>Process Mining (Tracer Plots) for Heart Failure </center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "Pre_heart_failure_dataframe = []\n",
    "Post_heart_failure_dataframe = []\n",
    "Common_heart_failure_dataframe = []\n",
    "combined_dataframe = []\n",
    "\n",
    "# Load the datasets (adjust paths as necessary)\n",
    "Pre_heart_failure_dataframe = pd.read_csv('Pre heart_failure COMMON with comorbidities.csv')\n",
    "Post_heart_failure_dataframe = pd.read_csv('Post heart_failure COMMON with comorbidities.csv')\n",
    "Common_heart_failure_dataframe = pd.read_csv('Combined heart_failure Common with comorbidities.csv')\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_dataframe = pd.concat([Pre_heart_failure_dataframe, Common_heart_failure_dataframe, Post_heart_failure_dataframe], ignore_index=True)\n",
    "\n",
    "# Drop duplicates from the combined dataframe\n",
    "combined_dataframe = combined_dataframe.drop_duplicates()\n",
    "combined_dataframe.head(3)\n",
    "\n",
    "# Replace specific heart_failure types with \"heart_failure\"\n",
    "heart_failure_conditions = ['I50.0', 'I50.1']\n",
    "combined_dataframe['Combined ICD10 Codes'] = combined_dataframe['Combined ICD10 Codes'].replace(heart_failure_conditions, 'heart_failure')\n",
    "\n",
    "# Convert Diagnosis Date to datetime format\n",
    "combined_dataframe['Combined ICD10 Diagnosis Date'] = pd.to_datetime(combined_dataframe['Combined ICD10 Diagnosis Date'])\n",
    "\n",
    "# Define relevant conditions and filter\n",
    "conditions = {\n",
    "    \"Essential (primary) hypertension (I10)\": \"I10\",\n",
    "    \"Atrial fibrillation and flutter (I48)\": \"I48\",\n",
    "    \"Pure hypercholesterolemia (E78.0)\": \"E78.0\",\n",
    "    \"Atherosclerotic heart disease (I25.1)\": \"I25.1\",\n",
    "    \"Type 2 diabetes mellitus without complications (E11.9)\": \"E11.9\",\n",
    "    \"Mitral (valve) insufficiency (I34.0)\": \"I34.0\",\n",
    "    \"Asthma, unspecified (J45.9)\": \"J45.9\",\n",
    "    \"heart_failure\": \"heart_failure\",\n",
    "}\n",
    "condition_codes = list(conditions.values())\n",
    "filtered_dataframe = combined_dataframe[combined_dataframe['Combined ICD10 Codes'].isin(condition_codes)]\n",
    "\n",
    "# Sort the dataframe by Participant ID and Diagnosis Date to maintain order of conditions\n",
    "filtered_dataframe = filtered_dataframe.sort_values(by=['Participant ID', 'Combined ICD10 Diagnosis Date'])\n",
    "\n",
    "# Group by Participant ID to create a list of ICD10 codes and dates for each participant, filtering for traces with 3 or more conditions\n",
    "participant_traces = (\n",
    "    filtered_dataframe.groupby('Participant ID')\n",
    "    .apply(lambda x: x[['Combined ICD10 Codes', 'Combined ICD10 Diagnosis Date']].values.tolist() if len(x) >= 3 else None)\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "participant_traces = pd.DataFrame(participant_traces, columns=['Traces'])\n",
    "\n",
    "# Count the frequency of each unique sequence of conditions (pathway)\n",
    "trace_frequencies = participant_traces['Traces'].apply(lambda trace: tuple([item[0] for item in trace])).value_counts().reset_index()\n",
    "trace_frequencies.columns = ['Activities', 'Frequency']\n",
    "\n",
    "\n",
    "\n",
    "# Filter out sequences that occur less than a threshold (e.g., 10 times)\n",
    "trace_frequencies = trace_frequencies[trace_frequencies['Frequency'] >= 1]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the total mean time for each pathway and between consecutive nodes\n",
    "mean_times = []\n",
    "mean_time_between_nodes = {}\n",
    "\n",
    "mean_times = []\n",
    "mean_time_between_nodes_list = []\n",
    "\n",
    "for activities in trace_frequencies['Activities']:\n",
    "    matching_participants = participant_traces[participant_traces['Traces'].apply(lambda trace: tuple([item[0] for item in trace]) == activities)]['Traces']\n",
    "    node_differences = {i: [] for i in range(len(activities) - 1)}\n",
    "\n",
    "    for trace in matching_participants:\n",
    "        for i in range(len(trace) - 1):\n",
    "            start_date = trace[i][1]\n",
    "            end_date = trace[i + 1][1]\n",
    "            node_diff_years = (end_date - start_date).days / 365.25\n",
    "            node_differences[i].append(node_diff_years)\n",
    "\n",
    "    total_cumulative_mean_time = 0\n",
    "    mean_times_for_nodes = []\n",
    "    for i in node_differences:\n",
    "        mean_time = sum(node_differences[i]) / len(node_differences[i]) if node_differences[i] else 0\n",
    "        mean_time_between_nodes[(activities[i], activities[i + 1])] = mean_time\n",
    "        total_cumulative_mean_time += mean_time\n",
    "        mean_times_for_nodes.append(mean_time)\n",
    "\n",
    "    total_mean_time = sum(mean_times_for_nodes)\n",
    "    mean_times.append(total_mean_time)\n",
    "    mean_time_between_nodes_list.append(mean_times_for_nodes)\n",
    "\n",
    "# Add Total Mean Time to the trace_frequencies DataFrame\n",
    "trace_frequencies['Total Mean Time'] = mean_times\n",
    "\n",
    "\n",
    "# Add Mean Time Between Nodes as separate columns\n",
    "max_nodes = max(len(times) for times in mean_time_between_nodes_list)\n",
    "for i in range(max_nodes):\n",
    "    trace_frequencies[f'Mean Time Node {i+1}-{i+2}'] = [\n",
    "        times[i] if i < len(times) else None for times in mean_time_between_nodes_list\n",
    "    ]\n",
    "\n",
    "# Replace NaN values with 0 in the trace_frequencies DataFrame\n",
    "#trace_frequencies = trace_frequencies.fillna(0)\n",
    "\n",
    "#display(trace_frequencies)\n",
    "\n",
    "# Update Total Mean Time column\n",
    "node_columns = [col for col in trace_frequencies.columns if col.startswith('Mean Time Node')]\n",
    "trace_frequencies['Total Mean Time'] = trace_frequencies[node_columns].sum(axis=1)\n",
    "\n",
    "# Sort pathways by the initial condition to create groups\n",
    "trace_frequencies['Group'] = trace_frequencies['Activities'].apply(lambda x: x[0])\n",
    "trace_frequencies = trace_frequencies.sort_values(by=['Group', 'Total Mean Time'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define the specific pathways you want to extract\n",
    "specific_traces = [\n",
    "    ('E11.9', 'I10', 'I48', 'heart_failure'),\n",
    "    ('E11.9', 'E78.0', 'I10', 'I25.1', 'heart_failure'),\n",
    "    ('E11.9', 'I10', 'E78.0', 'heart_failure'),    \n",
    "    ('E11.9', 'I10', 'heart_failure'),\n",
    "    ('E11.9', 'I10', 'I25.1', 'heart_failure'),\n",
    "    ('E11.9', 'E78.0', 'I10', 'heart_failure'),\n",
    "    \n",
    "    ('E78.0', 'I10', 'I48' ,'heart_failure'),\n",
    "    ('E78.0', 'I10', 'I25.1' ,'heart_failure'),\n",
    "    ('E78.0', 'I10','heart_failure'),\n",
    "    \n",
    "    ('I10', 'E78.0', 'I25.1','heart_failure'),\n",
    "    ('I10', 'E11.9' , 'E78.0', 'heart_failure'),\n",
    "    ('I10', 'I48', 'E78.0','heart_failure'),\n",
    "    ('I10', 'E11.9', 'heart_failure'),\n",
    "    ('I10', 'I48','heart_failure'),\n",
    "    ('I10', 'I25.1','heart_failure'),\n",
    "    \n",
    "    ('I25.1','E78.0', 'I10', 'heart_failure'),\n",
    "    ('I25.1','I10', 'heart_failure'),\n",
    "    \n",
    "    ('I48','I10', 'heart_failure'),\n",
    "    ('I48','I25.1', 'heart_failure'),\n",
    "    \n",
    "    ('J45.9','I10', 'heart_failure'),\n",
    "]\n",
    "\n",
    "# Filter the trace_frequencies DataFrame for these specific pathways\n",
    "trace_frequencies = trace_frequencies[trace_frequencies['Activities'].isin(specific_traces)]\n",
    "#display(trace_frequencies)\n",
    "\n",
    "# Define the color dictionary for the plot\n",
    "color_dict = {\n",
    "    'heart_failure': '#b3b3b3',\n",
    "    'I10': '#b3a3cc',\n",
    "    'I48': '#add8e6',\n",
    "    'E78.0': '#ddc4a1',\n",
    "    'I25.1': '#f4b0c8',\n",
    "    'E11.9': '#c4e3b3',\n",
    "    'I34.0': '#b3e2d4',\n",
    "    'J45.9': '#FFFF99',\n",
    "}\n",
    "\n",
    "# The plotting code remains unchanged, with \"PH\" replaced by \"heart_failure\" where necessary\n",
    "\n",
    "# Define the conversion function for formatting total mean time\n",
    "def convert_years_to_years_months(years):\n",
    "    if isinstance(years, (int, float)) and not pd.isna(years):\n",
    "        years_int = int(years)\n",
    "        months = round((years - years_int) * 12)\n",
    "        return f\"{years_int} yrs - {months} mos\"\n",
    "    return \"\"\n",
    "\n",
    "# Apply the conversion to 'Total Mean Time' and create a new column with formatted values\n",
    "trace_frequencies['Total Mean Time Formatted'] = trace_frequencies['Total Mean Time'].apply(convert_years_to_years_months)\n",
    "\n",
    "# Plotting the figure with a gap between nodes\n",
    "fig, ax = plt.subplots(figsize=(18, 11))\n",
    "gap = 0.25  # Gap between nodes\n",
    "frequency_position = max(len(t) for t in trace_frequencies['Activities']) + 2\n",
    "mean_time_position = frequency_position - 0.3\n",
    "\n",
    "\n",
    "\n",
    "# Filter out rows where heart_failure occurs before any other condition or appears more than once\n",
    "trace_frequencies = trace_frequencies[\n",
    "    trace_frequencies['Activities'].apply(\n",
    "        lambda x: all(x.index('heart_failure') > x.index(cond) for cond in x if cond != 'heart_failure') if 'heart_failure' in x else True\n",
    "    ) & trace_frequencies['Activities'].apply(\n",
    "        lambda x: x.count('heart_failure') <= 1  # Ensure heart_failure appears at most once\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Insert empty rows for grouping in the DataFrame\n",
    "rows = []\n",
    "for index, row in trace_frequencies.iterrows():\n",
    "    rows.append(row)\n",
    "    if index < len(trace_frequencies) - 1:\n",
    "        current_group = row['Group']\n",
    "        next_group = trace_frequencies.iloc[index + 1]['Group']\n",
    "        if current_group != next_group:\n",
    "            empty_row = pd.Series({\n",
    "                'Activities': None,\n",
    "                'Frequency': 0,\n",
    "                'Total Mean Time': 0,\n",
    "                'Group': \"\",\n",
    "                'Total Mean Time Formatted': \"\"\n",
    "            })\n",
    "            rows.append(empty_row)\n",
    "\n",
    "trace_frequencies = pd.DataFrame(rows).fillna(\"\").replace(0, \"\")\n",
    "\n",
    "display(trace_frequencies)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure all mean time columns are numeric\n",
    "mean_time_columns = [\n",
    "    'Mean Time Node 1-2', 'Mean Time Node 2-3', 'Mean Time Node 3-4',\n",
    "    'Mean Time Node 4-5', 'Mean Time Node 5-6', 'Mean Time Node 6-7'\n",
    "]\n",
    "\n",
    "# Convert columns to numeric, replacing errors with NaN\n",
    "trace_frequencies[mean_time_columns] = trace_frequencies[mean_time_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define a function to calculate the standard deviation for each row\n",
    "def calculate_row_std(row):\n",
    "    # Extract the mean time columns (drop NaN values)\n",
    "    node_times = row[mean_time_columns].dropna()\n",
    "    # Compute standard deviation\n",
    "    return node_times.std()\n",
    "\n",
    "# Apply the function to each row and create a new column for standard deviation\n",
    "trace_frequencies['Total Mean Time Std'] = trace_frequencies.apply(calculate_row_std, axis=1)\n",
    "\n",
    "# Replace NaN values with empty strings in the entire dataframe\n",
    "trace_frequencies = trace_frequencies.fillna('')\n",
    "\n",
    "# Display the updated dataframe\n",
    "display(trace_frequencies)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modified plotting loop\n",
    "for row, (trace, frequency, mean_time) in enumerate(zip(trace_frequencies[\"Activities\"], trace_frequencies[\"Frequency\"], trace_frequencies[\"Total Mean Time\"]), start=1):\n",
    "    if not trace:  # Skip empty rows for plotting\n",
    "        continue\n",
    "\n",
    "    for col, cond in enumerate(trace, start=1):\n",
    "        x_position = col + (col - 1) * gap\n",
    "        ax.add_patch(plt.Rectangle((x_position - 0.48, row - 0.44), 0.8, 0.92, facecolor=color_dict.get(cond, 'white'), edgecolor='black'))\n",
    "        ax.text(x_position - 0.06, row, cond, ha='center', va='center', fontsize=13)\n",
    "\n",
    "        # Add directed arrow between nodes if not the last node\n",
    "        if col < len(trace):\n",
    "            next_x_position = x_position + 1 + gap\n",
    "            ax.annotate(\n",
    "                '', xy=(next_x_position - 0.46, row), xytext=(x_position + 0.31, row),\n",
    "                arrowprops=dict(arrowstyle=\"->\", color='black', lw=0.9)\n",
    "            )\n",
    "\n",
    "            # Display mean time between nodes\n",
    "            mean_time_column = f'Mean Time Node {col}-{col+1}'\n",
    "            if mean_time_column in trace_frequencies.columns and 0 <= row - 1 < len(trace_frequencies):\n",
    "                mean_time_display = trace_frequencies.iloc[row - 1][mean_time_column]\n",
    "                if pd.notna(mean_time_display) and isinstance(mean_time_display, (int, float)):\n",
    "                    ax.text(\n",
    "                        (x_position + next_x_position) / 2 - 0.06, row - 0.25,\n",
    "                        f'{mean_time_display:.2f} yrs', ha='center', va='center', fontsize=12, color='black'\n",
    "                    )\n",
    "\n",
    "    # Display frequency and mean time at the end\n",
    "    ax.text(frequency_position, row, f'{frequency}', ha='center', va='center', color='grey', fontsize=11)\n",
    "    # Add grey block for Total Mean Time\n",
    "    ax.add_patch(plt.Rectangle((mean_time_position - 0.17, row - 0.45), 0.7, 0.9, facecolor='grey', edgecolor='white'))\n",
    "    formatted_mean_time = convert_years_to_years_months(mean_time)\n",
    "    ax.text(mean_time_position + 0.2, row, formatted_mean_time, ha='center', va='center', color='white', fontsize=13.5)\n",
    "\n",
    "# Add headings for the grey boxes\n",
    "plt.text(frequency_position - 6.5, -0.3, \"No. of\\n Individuals\", ha='center', va='center', fontsize=13, fontweight='bold')\n",
    "plt.text(mean_time_position + 0.2, -0.2, \"Total Mean\\n Time (yrs)\", ha='center', va='center', fontsize=13, fontweight='bold')\n",
    "\n",
    "\n",
    "# Set x-axis limits\n",
    "ax.set_xlim(0.5, mean_time_position + 0.5)\n",
    "\n",
    "# Manually set x-tick positions and labels\n",
    "ax.set_xticks([0.92, 2.17, 3.41, 4.68,6.00])\n",
    "ax.set_xticklabels(['1', '2', '3', '4','5'], fontsize=14)\n",
    "\n",
    "# Set y-axis limits and ticks\n",
    "ax.set_ylim(len(trace_frequencies) + 0.45, 0.55)\n",
    "ax.set_yticks(range(1, len(trace_frequencies) + 1))\n",
    "ax.set_yticklabels(trace_frequencies['Frequency'], fontsize=14)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel(\"Disease Sequence\", fontsize=14.5, fontweight='bold')\n",
    "ax.set_ylabel(\"Disease Pathways Leading to heart_failure Conditions\", fontsize=15, fontweight='bold', labelpad=20)\n",
    "\n",
    "# Adjust legend\n",
    "handles = [mpatches.Patch(color=color_dict[cond], label=key) for key, cond in conditions.items()]\n",
    "ax.legend(handles=handles, bbox_to_anchor=(0.5, -0.07), loc='upper center', ncol=3, fontsize=14, title_fontsize='12')\n",
    "\n",
    "# Hide right and top spines\n",
    "for spine in ['right', 'top']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "Pre_PH_dataframe = []\n",
    "Post_PH_dataframe = []\n",
    "Common_PH_dataframe = []\n",
    "Common_PH_dataframe = []\n",
    "trace_frequencies= []\n",
    "\n",
    "# Load the datasets (adjust paths as necessary)\n",
    "Pre_PH_dataframe = pd.read_csv('Pre-PH Common PH Icd10 Codes.csv')\n",
    "Post_PH_dataframe = pd.read_csv('Post-PH Common PH Icd10 Codes.csv')\n",
    "Common_PH_dataframe = pd.read_csv('Common-PH Common PH Icd10 Codes.csv')\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_dataframe = pd.concat([Pre_PH_dataframe, Common_PH_dataframe, Post_PH_dataframe], ignore_index=True)\n",
    "\n",
    "# Drop duplicates from the combined dataframe\n",
    "combined_dataframe = combined_dataframe.drop_duplicates()\n",
    "\n",
    "# Replace specific PH types with \"PH\"\n",
    "ph_conditions = [\"I27.0\", \"I27.2\", \"I27.9\"]\n",
    "combined_dataframe['ICD10 Codes'] = combined_dataframe['ICD10 Codes'].replace(ph_conditions, 'PH/COPD/HF')\n",
    "\n",
    "# Convert Diagnosis Date to datetime format\n",
    "combined_dataframe['Diagnosis Date'] = pd.to_datetime(combined_dataframe['Diagnosis Date'])\n",
    "\n",
    "# Define relevant conditions and filter\n",
    "conditions = {\n",
    "    \"Essential (primary) hypertension\": \"I10\",\n",
    "    \"Atrial fibrillation and flutter\": \"I48\",\n",
    "    \"Pure hypercholesterolemia\": \"E78.0\",\n",
    "    \"Atherosclerotic heart disease\": \"I25.1\",\n",
    "    \"Type 2 diabetes mellitus\": \"E11.9\",\n",
    "    \"Mitral (valve) insufficiency\": \"I34.0\",\n",
    "    \"Asthma\": \"J45.9\",\n",
    "    \"PH, COPD, HF Condition\": \"PH/COPD/HF\",\n",
    "}\n",
    "condition_codes = list(conditions.values())\n",
    "filtered_dataframe = combined_dataframe[combined_dataframe['ICD10 Codes'].isin(condition_codes)]\n",
    "\n",
    "# Sort the dataframe by Participant ID and Diagnosis Date to maintain order of conditions\n",
    "filtered_dataframe = filtered_dataframe.sort_values(by=['Participant ID', 'Diagnosis Date'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Group by Participant ID to create a list of ICD10 codes and dates for each participant, filtering for traces with 3 or more conditions\n",
    "participant_traces = (\n",
    "    filtered_dataframe.groupby('Participant ID')\n",
    "    .apply(lambda x: x[['ICD10 Codes', 'Diagnosis Date']].values.tolist() if len(x) >= 3 else None)\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "participant_traces = pd.DataFrame(participant_traces, columns=['Traces'])\n",
    "\n",
    "# Count the frequency of each unique sequence of conditions (pathway)\n",
    "trace_frequencies = participant_traces['Traces'].apply(lambda trace: tuple([item[0] for item in trace])).value_counts().reset_index()\n",
    "trace_frequencies.columns = ['Activities', 'Frequency']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter out sequences that occur less than a threshold (e.g., 10 times)\n",
    "trace_frequencies = trace_frequencies[trace_frequencies['Frequency'] >= 10]\n",
    "\n",
    "\n",
    "\n",
    "# Define a dictionary with the manually updated formatted values\n",
    "manual_ph_updates = {\n",
    "    ('I10', 'I48', 'PH/COPD/HF'): \"8 yrs - 4 mos ± 1.42 yrs \",\n",
    "    ('I10', 'I25.1', 'PH/COPD/HF'): \"5 yrs - 11 mos  ± 2.76 yrs\",\n",
    "    ('I10', 'E11.9', 'PH/COPD/HF'): \"8 yrs - 5 mos ± 2.33 yrs\",\n",
    "    ('I10', 'E78.0', 'I25.1','PH/COPD/HF'): \"9 yrs - 12 mos ± 1.96 yrs\",\n",
    "    ('I10', 'E11.9', 'E78.0','PH/COPD/HF'): \"9 yrs - 11 mos ± 1.18 yrs\",\n",
    "    ('I10', 'I48', 'E78.0','PH/COPD/HF'): \"8 yrs - 7 mos ± 1.16 yrs\",\n",
    "    \n",
    "    ('E78.0', 'I10', 'PH/COPD/HF'): \"5 yrs - 7 mos ± 1.34 yrs\",\n",
    "    ('E78.0', 'I10', 'I25.1','PH/COPD/HF'): \"6 yrs - 6 mos ± 2.34 yrs\",\n",
    "    ('E78.0', 'I10', 'I48','PH/COPD/HF'): \"6 yrs - 8 mos ± 1.39 yrs\",\n",
    "    \n",
    "    ('E11.9', 'I10', 'E78.0','PH/COPD/HF'): \"7 yrs - 11 mos ± 2.07 yrs\",\n",
    "    ('E11.9', 'I10', 'I48','PH/COPD/HF'): \"8 yrs - 8 mos ± 2.64 yrs\",\n",
    "    ('E11.9', 'E78.0' ,'I10', 'I25.1','PH/COPD/HF'): \"8 yrs - 2 mos ± 1.46 yrs\",\n",
    "    ('E11.9', 'I10', 'I25.1','PH/COPD/HF'): \"7 yrs - 0 mos ± 1.05 yrs\",\n",
    "    ('E11.9', 'E78.0', 'I10','PH/COPD/HF'): \"5 yrs - 8 mos ± 0.90 yrs\",\n",
    "    ('E11.9', 'I10','PH/COPD/HF'): \"7 yrs - 1 mos ± 2.53 yrs\",\n",
    "    \n",
    "    ('I48', 'I10', 'PH/COPD/HF'): \"8 yrs - 5 mos ± 0.29 yrs\",\n",
    "    ('I48', 'I25.1', 'PH/COPD/HF'): \"6 yrs - 3 mos ± 0.54 yrs\",\n",
    "    \n",
    "    ('I25.1', 'I10', 'PH/COPD/HF'): \"7 yrs - 3 mos ± 1.25 yrs\",\n",
    "    ('I25.1', 'E78.0' ,'I10', 'PH/COPD/HF'): \"8 yrs - 8 mos ± 1.93 yrs\",\n",
    "    \n",
    "    ('J45.9', 'I10', 'PH/COPD/HF'): \"10 yrs - 8 mos\t ± 1.53 yrs\",\n",
    "}\n",
    " \n",
    "\n",
    "# Define a dictionary with the updated Frequency values in the desired format\n",
    "updated_frequencies = {\n",
    "    ('I10', 'I48', 'PH/COPD/HF'): \"2 yrs - 11 mos ± 1.03 yrs\",\n",
    "    ('I10', 'I25.1', 'PH/COPD/HF'): \"4 yrs - 8 mos ± 0.83 yrs\",\n",
    "    ('I10', 'E11.9', 'PH/COPD/HF'): \"8 yrs - 2 mos ± 2.08 yrs\",\n",
    "    ('I10', 'E78.0', 'I25.1','PH/COPD/HF'): \"13 yrs - 8 mos ± 3.11 yrs\",\n",
    "    ('I10', 'E11.9', 'E78.0','PH/COPD/HF'): \"11 yrs - 11 mos ± 2.13 yrs\",\n",
    "    ('I10', 'I48', 'E78.0','PH/COPD/HF'): \"1 yr - 6 mos ± 0.01 yrs\",\n",
    "    \n",
    "    ('E78.0', 'I10', 'PH/COPD/HF'): \"3 yrs - 2 mos ± 0.86 yrs\",\n",
    "    ('E78.0', 'I10', 'I25.1','PH/COPD/HF'): \"5 yrs - 11 mos ± 3.11 yrs\",\n",
    "    ('E78.0', 'I10', 'I48','PH/COPD/HF'): \"8 yrs - 3 mos ± 2.37 yrs\",\n",
    "    \n",
    "    ('E11.9', 'I10', 'E78.0','PH/COPD/HF'): \"11 yrs - 10 mos ± 0.78 yrs\",\n",
    "    ('E11.9', 'I10', 'I48','PH/COPD/HF'): \"8 yrs - 3 mos ± 2.03 yrs\",\n",
    "    ('E11.9', 'E78.0' ,'I10', 'I25.1','PH/COPD/HF'): \"7 yrs - 11 mos ± 2.38 yrs\",\n",
    "    ('E11.9', 'I10', 'I25.1','PH/COPD/HF'): \"6 yrs - 9 mos ± 0.12 yrs\",\n",
    "    ('E11.9', 'E78.0', 'I10','PH/COPD/HF'): \"3 yrs - 6 mos ± 1.08 yrs\",\n",
    "    ('E11.9', 'I10','PH/COPD/HF'): \"2 yrs - 8 mos ± 0.82 yrs\",\n",
    "    \n",
    "    ('I48', 'I10', 'PH/COPD/HF'): \"6 yrs - 2 mos ± 1.97 yrs\",\n",
    "    ('I48', 'I25.1', 'PH/COPD/HF'): \"2 yrs - 5 mos ± 1.32 yrs\",\n",
    "    \n",
    "    ('I25.1', 'I10', 'PH/COPD/HF'): \"2 yrs - 11 mos ± 0.52 yrs\",\n",
    "    ('I25.1', 'E78.0' ,'I10', 'PH/COPD/HF'): \"4 yrs - 10 mos ± 0.91 yrs\",\n",
    "    \n",
    "    ('J45.9', 'I10', 'PH/COPD/HF'): \"0 yrs - 0 mos ± 0 yrs\",\n",
    "}\n",
    "\n",
    "# Manually specify values for Total Mean Time (Heart Failure Matched)\n",
    "\n",
    "manual_hf_timess = {\n",
    "    ('I10', 'I48', 'PH/COPD/HF'): \"5 yrs - 6 mos ± 0.01 yrs \",\n",
    "    ('I10', 'I25.1', 'PH/COPD/HF'): \"5 yrs - 1 mos ± 2.05 yrs\",\n",
    "    ('I10', 'E11.9', 'PH/COPD/HF'): \"10 yrs - 4 mos ± 2.14 yrs\",\n",
    "    ('I10', 'E78.0', 'I25.1','PH/COPD/HF'): \"11 yrs - 2 mos ± 0.81 yrs\",\n",
    "    ('I10', 'E11.9', 'E78.0','PH/COPD/HF'): \"11 yrs - 9 mos ± 1.98 yrs\",\n",
    "    ('I10', 'I48', 'E78.0','PH/COPD/HF'): \"11 yr - 11 mos ± 1.31 yrs\",\n",
    "    \n",
    "    ('E78.0', 'I10', 'PH/COPD/HF'): \"5 yrs - 7 mos ± 2.08 yrs\",\n",
    "    ('E78.0', 'I10', 'I25.1','PH/COPD/HF'): \"6 yrs - 2 mos ± 1.45 yrs\",\n",
    "    ('E78.0', 'I10', 'I48','PH/COPD/HF'): \"7 yrs - 3 mos ± 1.63 yrs\",\n",
    "    \n",
    "    ('E11.9', 'I10', 'E78.0','PH/COPD/HF'): \"7 yrs - 10 mos ± 2.29 yrs\",\n",
    "    ('E11.9', 'I10', 'I48','PH/COPD/HF'): \"5 yrs - 9 mos ± 0.16 yrs\",\n",
    "    ('E11.9', 'E78.0' ,'I10', 'I25.1','PH/COPD/HF'): \"8 yrs - 4 mos ± 1.81 yrs\",\n",
    "    ('E11.9', 'I10', 'I25.1','PH/COPD/HF'): \"8 yrs - 8 mos ± 1.96 yrs\",\n",
    "    ('E11.9', 'E78.0', 'I10','PH/COPD/HF'): \"10 yrs - 1 mos ± 1.97 yrs\",\n",
    "    ('E11.9', 'I10','PH/COPD/HF'): \"6 yrs - 0 mos ± 1.79 yrs\",\n",
    "    \n",
    "    ('I48', 'I10', 'PH/COPD/HF'): \"7 yrs - 7 mos ± 0.61 yrs\",\n",
    "    ('I48', 'I25.1', 'PH/COPD/HF'): \"1 yrs - 4 mos ± 1.35 yrs\",\n",
    "    \n",
    "    ('I25.1', 'I10', 'PH/COPD/HF'): \"9 yrs - 5 mos ± 1.35 yrs\",\n",
    "    ('I25.1', 'E78.0' ,'I10', 'PH/COPD/HF'): \"10 yrs - 5 mos ± 1.02 yrs\",\n",
    "    \n",
    "    ('J45.9', 'I10', 'PH/COPD/HF'): \"11 yrs - 2 mos ± 2.57 yrs\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Update the Frequency column in the DataFrame with formatted values\n",
    "trace_frequencies['Frequency'] = trace_frequencies['Activities'].apply(lambda x: updated_frequencies.get(tuple(x), x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#display(trace_frequencies)\n",
    "########################################################\n",
    "\n",
    "# Calculate the total mean time for each pathway and between consecutive nodes\n",
    "mean_times = []\n",
    "mean_time_between_nodes = {}\n",
    "\n",
    "\n",
    "mean_times = []\n",
    "mean_time_between_nodes_list = []  # List to store mean times between nodes for each pathway\n",
    "\n",
    "for activities in trace_frequencies['Activities']:\n",
    "    matching_participants = participant_traces[participant_traces['Traces'].apply(lambda trace: tuple([item[0] for item in trace]) == activities)]['Traces']\n",
    "    node_differences = {i: [] for i in range(len(activities) - 1)}  # To store mean time between nodes\n",
    "\n",
    "    # Calculate time between each node for all matching traces\n",
    "    for trace in matching_participants:\n",
    "        for i in range(len(trace) - 1):\n",
    "            start_date = trace[i][1]\n",
    "            end_date = trace[i + 1][1]\n",
    "            node_diff_years = (end_date - start_date).days / 365.25\n",
    "            node_differences[i].append(node_diff_years)\n",
    "\n",
    "    # Calculate mean time between nodes and store cumulative sum\n",
    "    total_cumulative_mean_time = 0\n",
    "    mean_times_for_nodes = []  # To store mean times between nodes for the current pathway\n",
    "    for i in node_differences:\n",
    "        mean_time = sum(node_differences[i]) / len(node_differences[i]) if node_differences[i] else 0\n",
    "        mean_time_between_nodes[(activities[i], activities[i + 1])] = mean_time\n",
    "        total_cumulative_mean_time += mean_time  # Accumulate mean times for Total Mean Time\n",
    "        mean_times_for_nodes.append(mean_time)  # Append mean time for this node transition\n",
    "\n",
    "    total_mean_time = sum(mean_times_for_nodes)  # Calculate the total mean time as the sum of mean times between nodes\n",
    "    mean_times.append(total_mean_time)  # Store the corrected cumulative mean time\n",
    "    mean_time_between_nodes_list.append(mean_times_for_nodes)  # Store list of mean times for the pathway\n",
    "\n",
    "# Add Total Mean Time to the trace_frequencies DataFrame\n",
    "trace_frequencies['Total Mean Time'] = mean_times\n",
    "\n",
    "# Add Mean Time Between Nodes as separate columns\n",
    "max_nodes = max(len(times) for times in mean_time_between_nodes_list)  # Find max number of nodes in any pathway\n",
    "for i in range(max_nodes):\n",
    "    trace_frequencies[f'Mean Time Node {i+1}-{i+2}'] = [\n",
    "        times[i] if i < len(times) else None for times in mean_time_between_nodes_list\n",
    "    ]\n",
    "\n",
    " \n",
    "# Display the updated DataFrame\n",
    "# Replace NaN values with 0 in the trace_frequencies DataFrame\n",
    "trace_frequencies = trace_frequencies.fillna(0)\n",
    "#display(trace_frequencies)\n",
    "\n",
    "# Sum the values from Mean Time Node columns to update the Total Mean Time column\n",
    "node_columns = [col for col in trace_frequencies.columns if col.startswith('Mean Time Node')]\n",
    "trace_frequencies['Total Mean Time'] = trace_frequencies[node_columns].sum(axis=1)\n",
    "\n",
    "# Remove the specific row where Activities contains (J45.9, I10, PH)\n",
    "trace_frequencies = trace_frequencies[trace_frequencies['Activities'] != ('J45.9', 'I10', 'PH/COPD/HF')]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#display(trace_frequencies)\n",
    "\n",
    "trace_frequencies['Group'] = trace_frequencies['Activities'].apply(lambda x: x[0])  # Group by first condition\n",
    "\n",
    "\n",
    "trace_frequencies = trace_frequencies.sort_values(by=['Group', 'Total Mean Time'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Remove specific traces by index (15 and 17) - subtracting 1 for zero-based indexing\n",
    "trace_frequencies = trace_frequencies.drop(index=[14, 16]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data for plotting\n",
    "data_dict = {\n",
    "    \"Trace\": trace_frequencies['Activities'].tolist(),\n",
    "    \"Frequency\": trace_frequencies['Frequency'].tolist(),\n",
    "    \"Total Mean Time\": trace_frequencies['Total Mean Time'].tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "# Map each condition to a color for the plot\n",
    "color_dict = {\n",
    "    'PH/COPD/HF': '#b3b3b3',\n",
    "    'I10': '#b3a3cc',\n",
    "    'I48': '#add8e6',\n",
    "    'E78.0': '#ddc4a1',\n",
    "    'I25.1': '#f4b0c8',\n",
    "    'E11.9': '#c4e3b3',\n",
    "    'I34.0': '#b3e2d4',\n",
    "    'J45.9': '#FFFF99',\n",
    "}\n",
    "\n",
    "\n",
    "# Define the conversion function\n",
    "def convert_years_to_years_months(years):\n",
    "    if isinstance(years, (int, float)) and not pd.isna(years):\n",
    "        years_int = int(years)\n",
    "        months = round((years - years_int) * 12)\n",
    "        return f\"{years_int} yrs - {months} mos\"\n",
    "    return \"\"  # Return an empty string if the input is not a number\n",
    "\n",
    "# Apply the conversion to 'Total Mean Time' and create a new column with formatted values\n",
    "trace_frequencies['Total Mean Time Formatted'] = trace_frequencies['Total Mean Time'].apply(convert_years_to_years_months)\n",
    "\n",
    "\n",
    "# Prepare data for plotting\n",
    "data_dict = {\n",
    "    \"Trace\": trace_frequencies['Activities'].tolist(),\n",
    "    \"Frequency\": trace_frequencies['Frequency'].tolist(),\n",
    "    \"Total Mean Time\": trace_frequencies['Total Mean Time'].tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "# Apply manual updates to the 'Total Mean Time Formatted' column\n",
    "trace_frequencies['Total Mean Time Formatted'] = trace_frequencies['Activities'].apply(\n",
    "    lambda x: manual_ph_updates.get(tuple(x), trace_frequencies.loc[trace_frequencies['Activities'] == x, 'Total Mean Time Formatted'].values[0])\n",
    ")\n",
    "#display(trace_frequencies)\n",
    "\n",
    "# Plotting the figure with a gap between nodes\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "gap = -0.39  # Gap between nodes\n",
    "frequency_position = max(len(t) for t in data_dict[\"Trace\"]) + 2\n",
    "mean_time_position = frequency_position + 0.05\n",
    "heart_failure_position = mean_time_position + 1.5  # Adjust the position for the new column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure data_dict is a DataFrame before iterating\n",
    "if isinstance(data_dict, dict):\n",
    "    data_dict = pd.DataFrame(data_dict)\n",
    "\n",
    "rows = []\n",
    "for index, row in data_dict.iterrows():\n",
    "    rows.append(row)\n",
    "    # Insert an empty row based on a condition (e.g., after each group)\n",
    "    if index < len(data_dict) - 1:  # Add condition to avoid unnecessary last row gap if needed\n",
    "        current_group = row['Trace'][0] if isinstance(row['Trace'], tuple) else None\n",
    "        next_group = data_dict.iloc[index + 1]['Trace'][0] if isinstance(data_dict.iloc[index + 1]['Trace'], tuple) else None\n",
    "        if current_group != next_group:\n",
    "            empty_row = pd.Series({'Trace': None, 'Frequency': 0, 'Total Mean Time': 0})\n",
    "            rows.append(empty_row)\n",
    "\n",
    "# Convert the modified list of rows back to a DataFrame\n",
    "data_dict = pd.DataFrame(rows).fillna(\"\").replace(0, \"\")\n",
    "\n",
    "\n",
    "\n",
    "# Insert empty rows in trace_frequencies based on group change\n",
    "rows = []\n",
    "for index, row in trace_frequencies.iterrows():\n",
    "    rows.append(row)\n",
    "    # Add an empty row after a change in the first element of 'Activities'\n",
    "    if index < len(trace_frequencies) - 1:  # Ensure we don't add an unnecessary row at the end\n",
    "        current_group = row['Activities'][0] if isinstance(row['Activities'], tuple) else None\n",
    "        next_group = trace_frequencies.iloc[index + 1]['Activities'][0] if isinstance(trace_frequencies.iloc[index + 1]['Activities'], tuple) else None\n",
    "        if current_group != next_group:\n",
    "            # Create an empty row with default values (adjust as necessary)\n",
    "            empty_row = pd.Series({\n",
    "                'Activities': None,\n",
    "                'Frequency': 0,\n",
    "                'Total Mean Time': 0,\n",
    "                'Mean Time Node 1-2': 0,\n",
    "                'Mean Time Node 2-3': 0,\n",
    "                'Mean Time Node 3-4': 0,\n",
    "                'Mean Time Node 4-5': 0,\n",
    "                'Group': \"\",\n",
    "                'Total Mean Time Formatted': \"\"\n",
    "            })\n",
    "            rows.append(empty_row)\n",
    "\n",
    "\n",
    "\n",
    "         \n",
    "         \n",
    "            \n",
    "# Convert the modified list of rows back to a DataFrame\n",
    "trace_frequencies = pd.DataFrame(rows).fillna(\"\").replace(0, \"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter out rows where PH occurs before any other condition\n",
    "trace_frequencies = trace_frequencies[\n",
    "    trace_frequencies['Activities'].apply(\n",
    "        lambda x: all(x.index('PH/COPD/HF') > x.index(cond) for cond in x if cond != 'PH/COPD/HF') if 'PH/COPD/HF' in x else True\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Prepare the data dictionary for plotting with updated frequencies\n",
    "data_dict = {\n",
    "    \"Trace\": trace_frequencies['Activities'].tolist(),\n",
    "    \"Frequency\": trace_frequencies['Frequency'].tolist(),\n",
    "    \"Total Mean Time\": trace_frequencies['Total Mean Time'].tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Modified plotting loop with improved handling of indexing\n",
    "for row, (trace, frequency, mean_time) in enumerate(zip(trace_frequencies[\"Activities\"], trace_frequencies[\"Frequency\"], trace_frequencies[\"Total Mean Time\"]), start=1):\n",
    "    if not trace:  # Skip empty rows for plotting\n",
    "        continue\n",
    "\n",
    "    for col, cond in enumerate(trace, start=1):\n",
    "        x_position = col + (col - 1) * gap  # Add gap between nodes\n",
    "        ax.add_patch(plt.Rectangle((x_position - 0.49, row - 0.45), 0.6, 0.9, facecolor=color_dict.get(cond, 'white'), edgecolor='black'))\n",
    "        ax.text(x_position - 0.18, row, cond, ha='center', va='center')\n",
    "\n",
    "        # Add directed arrow between nodes if not the last node\n",
    "        #if col < len(trace):\n",
    "        #    # Manually control the tail and head of the arrow\n",
    "        #    tail_x = x_position + 0.1  # Tail position (adjust this value to move the tail)\n",
    "        #    tail_y = row  # Tail vertical alignment\n",
    "        #    head_x = x_position + 1 + gap - 0.46  # Head position (adjust this value to move the head)\n",
    "        #    head_y = row  # Head vertical alignment\n",
    "            \n",
    "        #    ax.annotate(\n",
    "         #       '',\n",
    "         #       xy=(head_x, head_y),   # Arrow head position\n",
    "         #       xytext=(tail_x, tail_y),  # Arrow tail position\n",
    "         #       arrowprops=dict(arrowstyle=\"->\", color='black', lw=0.8)  # Arrow properties\n",
    "         #   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Display frequency and mean time at the end\n",
    "    ax.add_patch(plt.Rectangle((frequency_position - 2.20, row - 0.45), 1.1, 0.99, facecolor='grey', edgecolor='white'))\n",
    "    ax.text(frequency_position - 1.65, row, f'{frequency}', ha='center', va='center', color='white')\n",
    "    ax.add_patch(plt.Rectangle((mean_time_position - 3.42, row - 0.45), 1.1, 0.99, facecolor='grey', edgecolor='white'))\n",
    "    \n",
    "    # Use the formatted mean time for displaying it\n",
    "    #formatted_mean_time = convert_years_to_years_months(mean_time)\n",
    "    #ax.text(mean_time_position - 1.77, row, formatted_mean_time, ha='center', va='center', color='white')\n",
    "    # Use the manually updated 'Total Mean Time Formatted' values\n",
    "    formatted_mean_time = trace_frequencies['Total Mean Time Formatted'].iloc[row - 1]\n",
    "    ax.text(mean_time_position - 2.87, row, formatted_mean_time, ha='center', va='center', color='white')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add grey box and text for Heart Failure Matched\n",
    "    ax.add_patch(plt.Rectangle((heart_failure_position - 2.57, row - 0.45), 1.1, 0.99, facecolor='grey', edgecolor='white'))\n",
    "    current_activities = trace_frequencies['Activities'].iloc[row - 1]  # Get the current activities tuple\n",
    "    formatted_hf_time = manual_hf_timess.get(current_activities, \"\")  # Retrieve value from dictionary\n",
    "    ax.text(heart_failure_position - 2.04, row, formatted_hf_time, ha='center', va='center', color='white')\n",
    "    #formatted_hf_time = trace_frequencies['Total Mean Time Formatted'].iloc[row - 1]  # Adjust index for correct row\n",
    "    #ax.text(heart_failure_position - 1.61, row, formatted_hf_time, ha='center', va='center', color='white')\n",
    "\n",
    "\n",
    "\n",
    "# Add headings for the grey boxes\n",
    "plt.text(frequency_position - 1.60, -0.2, \"Total Mean Time ± Std. dev.\\n(COPD Matched)\", ha='center', va='center', fontsize=10)\n",
    "plt.text(mean_time_position - 2.91, -0.2, \"Total Mean Time ± Std. dev.\\n(PH Cohort)\", ha='center', va='center', fontsize=10)\n",
    "plt.text(heart_failure_position - 2.05, -0.2, \"Total Mean Time ± Std. dev.\\n(Heart Failure Matched)\", ha='center', va='center',fontsize=10)\n",
    "\n",
    "\n",
    "# Set x-axis limits\n",
    "ax.set_xlim(0.5, mean_time_position + 0.5)\n",
    "\n",
    "# Manually set x-tick positions and labels\n",
    "ax.set_xticks([0.8, 1.41, 2.02, 2.67, 3.25])\n",
    "ax.set_xticklabels(['1', '2', '3', '4', '5'])\n",
    "\n",
    "# Set y-axis limits and ticks\n",
    "ax.set_ylim(len(data_dict[\"Trace\"]) + 0.45, 0.55)\n",
    "ax.set_yticks([])\n",
    "#ax.set_yticks(range(1, len(data_dict[\"Frequency\"]) + 1))\n",
    "#ax.set_yticklabels(data_dict[\"Frequency\"])  # Replace y-tick values with \"Frequency\" values\n",
    "\n",
    "# Set axis labels with increased font size\n",
    "ax.set_xlabel(\"Disease Sequence\", fontsize=13)\n",
    "ax.set_ylabel(\"Disease Pathways\", fontsize=13, labelpad=10)\n",
    "\n",
    "# Adjust legend creation to show full names\n",
    "handles = [mpatches.Patch(color=color_dict[cond], label=key) for key, cond in conditions.items()]\n",
    "ax.legend(handles=handles, bbox_to_anchor=(0.5, -0.1), loc='upper center', ncol=4, fontsize=10, title_fontsize='11')\n",
    "\n",
    "# Hide right and top spines for better presentation\n",
    "for dir in ['right', 'top']:\n",
    "    ax.spines[dir].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
